{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "# def printLines(file, n=10):\n",
    "#     with open(file, 'rb') as datafile:\n",
    "#         lines = datafile.readlines()\n",
    "#     for line in lines[:n]:\n",
    "#         print(line)\n",
    "\n",
    "# printLines(os.path.join(corpus, \"movie_lines.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splits each line of the file into a dictionary of fields\n",
    "# def loadLines(fileName, fields):\n",
    "#     lines = {}\n",
    "#     with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "#         for line in f:\n",
    "#             values = line.split(\" +++$+++ \")\n",
    "#             # Extract fields\n",
    "#             lineObj = {}\n",
    "#             for i, field in enumerate(fields):\n",
    "#                 lineObj[field] = values[i]\n",
    "#             lines[lineObj['lineID']] = lineObj\n",
    "#     return lines\n",
    "\n",
    "\n",
    "# # Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\n",
    "# def loadConversations(fileName, lines, fields):\n",
    "#     conversations = []\n",
    "#     with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "#         for line in f:\n",
    "#             values = line.split(\" +++$+++ \")\n",
    "#             # Extract fields\n",
    "#             convObj = {}\n",
    "#             for i, field in enumerate(fields):\n",
    "#                 convObj[field] = values[i]\n",
    "#             # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
    "#             utterance_id_pattern = re.compile('L[0-9]+')\n",
    "#             lineIds = utterance_id_pattern.findall(convObj[\"utteranceIDs\"])\n",
    "#             # Reassemble lines\n",
    "#             convObj[\"lines\"] = []\n",
    "#             for lineId in lineIds:\n",
    "#                 convObj[\"lines\"].append(lines[lineId])\n",
    "#             conversations.append(convObj)\n",
    "#     return conversations\n",
    "\n",
    "\n",
    "# # Extracts pairs of sentences from conversations\n",
    "# def extractSentencePairs(conversations):\n",
    "#     qa_pairs = []\n",
    "#     for conversation in conversations:\n",
    "#         # Iterate over all the lines of the conversation\n",
    "#         for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "#             inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "#             targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "#             # Filter wrong samples (if one of the lists is empty)\n",
    "#             if inputLine and targetLine:\n",
    "#                 qa_pairs.append([inputLine, targetLine])\n",
    "#     return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splits each line of the file into a dictionary of fields\n",
    "# def loadLines(fileName, fields):\n",
    "#     lines = {}\n",
    "#     with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "#         for line in f:\n",
    "#             values = line.split(\" +++$+++ \")\n",
    "#             # Extract fields\n",
    "#             lineObj = {}\n",
    "#             for i, field in enumerate(fields):\n",
    "#                 lineObj[field] = values[i]\n",
    "#             lines[lineObj['lineID']] = lineObj\n",
    "#     return lines\n",
    "\n",
    "\n",
    "# # Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\n",
    "# def loadConversations(fileName, lines, fields):\n",
    "#     conversations = []\n",
    "#     with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "#         for line in f:\n",
    "#             values = line.split(\" +++$+++ \")\n",
    "#             # Extract fields\n",
    "#             convObj = {}\n",
    "#             for i, field in enumerate(fields):\n",
    "#                 convObj[field] = values[i]\n",
    "#             # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
    "#             utterance_id_pattern = re.compile('L[0-9]+')\n",
    "#             lineIds = utterance_id_pattern.findall(convObj[\"utteranceIDs\"])\n",
    "#             # Reassemble lines\n",
    "#             convObj[\"lines\"] = []\n",
    "#             for lineId in lineIds:\n",
    "#                 convObj[\"lines\"].append(lines[lineId])\n",
    "#             conversations.append(convObj)\n",
    "#     return conversations\n",
    "\n",
    "\n",
    "# # Extracts pairs of sentences from conversations\n",
    "# def extractSentencePairs(conversations):\n",
    "#     qa_pairs = []\n",
    "#     for conversation in conversations:\n",
    "#         # Iterate over all the lines of the conversation\n",
    "#         for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "#             inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "#             targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "#             # Filter wrong samples (if one of the lists is empty)\n",
    "#             if inputLine and targetLine:\n",
    "#                 qa_pairs.append([inputLine, targetLine])\n",
    "#     return qa_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define path to new file\n",
    "# datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
    "\n",
    "# delimiter = '\\t'\n",
    "# # Unescape the delimiter\n",
    "# delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# # Initialize lines dict, conversations list, and field ids\n",
    "# lines = {}\n",
    "# conversations = []\n",
    "# MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
    "# MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "\n",
    "# # Load lines and process conversations\n",
    "# print(\"\\nProcessing corpus...\")\n",
    "# lines = loadLines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\n",
    "# print(\"\\nLoading conversations...\")\n",
    "# conversations = loadConversations(os.path.join(corpus, \"movie_conversations.txt\"),\n",
    "#                                   lines, MOVIE_CONVERSATIONS_FIELDS)\n",
    "\n",
    "# # Write new csv file\n",
    "# print(\"\\nWriting newly formatted file...\")\n",
    "# with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "#     writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "#     for pair in extractSentencePairs(conversations):\n",
    "#         writer.writerow(pair)\n",
    "\n",
    "# # Print a sample of lines\n",
    "# print(\"\\nSample lines from file:\")\n",
    "# printLines(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"splite_data/train_unclean_data\"\n",
    "test_datafile = \"splite_data/test_data\"\n",
    "import json\n",
    "\n",
    "MIN_LENGHT = 20\n",
    "def load_data(path):\n",
    "    lines = open(path).readlines()\n",
    "    data = [json.loads(x) for x in lines]\n",
    "    data2 = [item for item in data if len(item) > MIN_LENGHT]\n",
    "    return data2\n",
    "\n",
    "def split2line(l):\n",
    "    split_token = [\";\", \"{\", \"}\"]\n",
    "    result = []\n",
    "    line = []\n",
    "    for item in l:\n",
    "        line.append(item)\n",
    "        if item in split_token:\n",
    "            result.append(line)\n",
    "            line = []\n",
    "    result.append(line)\n",
    "    return result\n",
    "\n",
    "def split2pair(l):\n",
    "    result = []\n",
    "    for i in range(1, len(l)):\n",
    "        input = []\n",
    "        for j in range(i):\n",
    "            input += l[j]\n",
    "        output = l[i]\n",
    "        result.append((input.copy(),output.copy()))\n",
    "    return result\n",
    "\n",
    "def split2pair2(l):\n",
    "    result = []\n",
    "    inputstr = []\n",
    "    for i in range(1, len(l)-1):\n",
    "        inputstr += l[i - 1]\n",
    "        outputstr = l[i]\n",
    "        result.append((inputstr.copy(),outputstr.copy()))\n",
    "    # for i in range(1, len(l)):\n",
    "    #     input = []\n",
    "    #     for j in range(i):\n",
    "    #         input += l[j]\n",
    "    #         for k in range(len(l[i])):\n",
    "    #             input += l[i][:k]\n",
    "    #             output = l[i][k:]\n",
    "    #             result.append((input.copy(),output.copy()))\n",
    "    return result\n",
    "    \n",
    "def wrap_s2p(raw_data):\n",
    "    data5 = []\n",
    "    for i, item in enumerate(raw_data):\n",
    "        data5 += split2pair(item)\n",
    "    return [(\" \".join(line[0]), \" \".join(line[1])) for line in data5]\n",
    "\n",
    "def wrap_s2p2(raw_data):\n",
    "    data5 = []\n",
    "    for i, item in enumerate(raw_data):\n",
    "        data5 += split2pair2(item)\n",
    "        # print(len(data5))\n",
    "        if len(data5) > 100000:\n",
    "            break\n",
    "    return [(\" \".join(line[0]), \" \".join(line[1])) for line in data5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 100025 sentence pairs\n",
      "Trimmed to 63020 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 44386\n",
      "\n",
      "pairs:\n",
      "('public String mapMethodDesc ( String desc ) {', 'if ( \" \" . equals ( desc ) ) {')\n",
      "('public String mapMethodDesc ( String desc ) { if ( \" \" . equals ( desc ) ) {', 'return desc ;')\n",
      "('public String mapMethodDesc ( String desc ) { if ( \" \" . equals ( desc ) ) { return desc ;', '}')\n",
      "('public String mapMethodDesc ( String desc ) { if ( \" \" . equals ( desc ) ) { return desc ; }', 'Type [ ] args = Type . getArgumentTypes ( desc ) ;')\n",
      "('public String mapMethodDesc ( String desc ) { if ( \" \" . equals ( desc ) ) { return desc ; } Type [ ] args = Type . getArgumentTypes ( desc ) ;', 'StringBuilder sb = new StringBuilder ( \" \" ) ;')\n",
      "('public String mapMethodDesc ( String desc ) { if ( \" \" . equals ( desc ) ) { return desc ; } Type [ ] args = Type . getArgumentTypes ( desc ) ; StringBuilder sb = new StringBuilder ( \" \" ) ;', 'for ( int i = 0 ;')\n",
      "('public String mapMethodDesc ( String desc ) { if ( \" \" . equals ( desc ) ) { return desc ; } Type [ ] args = Type . getArgumentTypes ( desc ) ; StringBuilder sb = new StringBuilder ( \" \" ) ; for ( int i = 0 ;', 'i < args . length ;')\n",
      "('public String mapMethodDesc ( String desc ) { if ( \" \" . equals ( desc ) ) { return desc ; } Type [ ] args = Type . getArgumentTypes ( desc ) ; StringBuilder sb = new StringBuilder ( \" \" ) ; for ( int i = 0 ; i < args . length ;', 'i ++ ) {')\n",
      "('public String mapMethodDesc ( String desc ) { if ( \" \" . equals ( desc ) ) { return desc ; } Type [ ] args = Type . getArgumentTypes ( desc ) ; StringBuilder sb = new StringBuilder ( \" \" ) ; for ( int i = 0 ; i < args . length ; i ++ ) {', 'sb . append ( mapDesc ( args [ i ] . getDescriptor ( ) ) ) ;')\n",
      "('public String mapMethodDesc ( String desc ) { if ( \" \" . equals ( desc ) ) { return desc ; } Type [ ] args = Type . getArgumentTypes ( desc ) ; StringBuilder sb = new StringBuilder ( \" \" ) ; for ( int i = 0 ; i < args . length ; i ++ ) { sb . append ( mapDesc ( args [ i ] . getDescriptor ( ) ) ) ;', '}')\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 100  # Maximum sentence length to consider\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    # s = unicodeToAscii(s.lower().strip())\n",
    "    # s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    # s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    # s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(datafile,test_datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    train_data = load_data(datafile)\n",
    "    train_data = [split2line(item) for item in train_data]\n",
    "    train_data = wrap_s2p2(train_data)\n",
    "    # lines = open(datafile, encoding='utf-8').\\\n",
    "    #     read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    # pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    pairs = train_data\n",
    "    test_data = load_data(test_datafile)\n",
    "    test_data = [split2line(item) for item in test_data]\n",
    "    test_data = wrap_s2p2(test_data)\n",
    "    test_pairs = test_data\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs, test_pairs\n",
    "\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus, corpus_name, datafile,test_datafile, save_dir):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs, test_pairs = readVocs(datafile,test_datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    test_pairs = filterPairs(test_pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs + test_pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs, test_pairs\n",
    "\n",
    "\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs, test_pairs = loadPrepareData(corpus, corpus_name, datafile,test_datafile, save_dir)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"getQualifiers\" in voc.word2index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 39580 / 44383 = 0.8918\n",
      "Trimmed from 63020 pairs to 60070, 0.9532 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[    3,     3,     3,     3,    60],\n",
      "        [12701,   183,   826,    98,  9426],\n",
      "        [12702,    12, 19201, 17169,     6],\n",
      "        [    6,   360,     6,     6,  3727],\n",
      "        [    4,    12,     8,     4,  2991],\n",
      "        [ 2366,     4,     9,  1335,    54],\n",
      "        [    8, 14828,    45,    54,  9427],\n",
      "        [    9,     6,    21,     4,  1069],\n",
      "        [12703,     8,     6,   737,     8],\n",
      "        [12704,     9,    45,     8,     9],\n",
      "        [   21,   183,    46,     9,   193],\n",
      "        [12705,    12,   936,  1189,    12],\n",
      "        [    6,   360,    47,     6,  2991],\n",
      "        [    8,    12,     8,  1335,    21],\n",
      "        [   15,   117,    15,    54,  2991],\n",
      "        [   27,  2446, 19202,   737,    15],\n",
      "        [12706,    21,    21,     8,     2],\n",
      "        [   21, 10386,   471,    15,     0],\n",
      "        [12704,    15,     6,     2,     0],\n",
      "        [   12,    10,     8,     0,     0],\n",
      "        [   40,     6,    12,     0,     0],\n",
      "        [    6,  2446,  4942,     0,     0],\n",
      "        [    8,   120,     6,     0,     0],\n",
      "        [   15,   183,     8,     0,     0],\n",
      "        [   26,    12,    15,     0,     0],\n",
      "        [    6,   360,   797,     0,     0],\n",
      "        [   27,    12,     6,     0,     0],\n",
      "        [ 1441,     4,     8,     0,     0],\n",
      "        [   21,     8,    15,     0,     0],\n",
      "        [   29,     9,     2,     0,     0],\n",
      "        [   15,     2,     0,     0,     0],\n",
      "        [ 1441,     0,     0,     0,     0],\n",
      "        [   30,     0,     0,     0,     0],\n",
      "        [12706,     0,     0,     0,     0],\n",
      "        [   15,     0,     0,     0,     0],\n",
      "        [ 1441,     0,     0,     0,     0],\n",
      "        [   32,     0,     0,     0,     0],\n",
      "        [    8,     0,     0,     0,     0],\n",
      "        [    9,     0,     0,     0,     0],\n",
      "        [12701,     0,     0,     0,     0],\n",
      "        [ 2441,     0,     0,     0,     0],\n",
      "        [   21,     0,     0,     0,     0],\n",
      "        [12704,     0,     0,     0,     0],\n",
      "        [   12,     0,     0,     0,     0],\n",
      "        [  542,     0,     0,     0,     0],\n",
      "        [    6,     0,     0,     0,     0],\n",
      "        [ 1441,     0,     0,     0,     0],\n",
      "        [    8,     0,     0,     0,     0],\n",
      "        [   15,     0,     0,     0,     0],\n",
      "        [    4,     0,     0,     0,     0],\n",
      "        [12707,     0,     0,     0,     0],\n",
      "        [   21,     0,     0,     0,     0],\n",
      "        [ 2441,     0,     0,     0,     0],\n",
      "        [   12,     0,     0,     0,     0],\n",
      "        [12708,     0,     0,     0,     0],\n",
      "        [    6,     0,     0,     0,     0],\n",
      "        [    8,     0,     0,     0,     0],\n",
      "        [   15,     0,     0,     0,     0],\n",
      "        [   10,     0,     0,     0,     0],\n",
      "        [    6,     0,     0,     0,     0],\n",
      "        [ 2366,     0,     0,     0,     0],\n",
      "        [   12,     0,     0,     0,     0],\n",
      "        [   13,     0,     0,     0,     0],\n",
      "        [    6,     0,     0,     0,     0],\n",
      "        [12707,     0,     0,     0,     0],\n",
      "        [    8,     0,     0,     0,     0],\n",
      "        [   38,     0,     0,     0,     0],\n",
      "        [  291,     0,     0,     0,     0],\n",
      "        [    8,     0,     0,     0,     0],\n",
      "        [   14,     0,     0,     0,     0],\n",
      "        [ 2441,     0,     0,     0,     0],\n",
      "        [   15,     0,     0,     0,     0],\n",
      "        [   16,     0,     0,     0,     0],\n",
      "        [ 1437,     0,     0,     0,     0],\n",
      "        [ 1438,     0,     0,     0,     0],\n",
      "        [   21,     0,     0,     0,     0],\n",
      "        [ 1439,     0,     0,     0,     0],\n",
      "        [    6,     0,     0,     0,     0],\n",
      "        [    8,     0,     0,     0,     0],\n",
      "        [   15,     0,     0,     0,     0],\n",
      "        [   27,     0,     0,     0,     0],\n",
      "        [ 1440,     0,     0,     0,     0],\n",
      "        [   21,     0,     0,     0,     0],\n",
      "        [ 1438,     0,     0,     0,     0],\n",
      "        [   12,     0,     0,     0,     0],\n",
      "        [   40,     0,     0,     0,     0],\n",
      "        [    6,     0,     0,     0,     0],\n",
      "        [    8,     0,     0,     0,     0],\n",
      "        [   15,     0,     0,     0,     0],\n",
      "        [   26,     0,     0,     0,     0],\n",
      "        [    6,     0,     0,     0,     0],\n",
      "        [   27,     0,     0,     0,     0],\n",
      "        [ 1441,     0,     0,     0,     0],\n",
      "        [   21,     0,     0,     0,     0],\n",
      "        [   29,     0,     0,     0,     0],\n",
      "        [   15,     0,     0,     0,     0],\n",
      "        [    2,     0,     0,     0,     0]])\n",
      "lengths: tensor([97, 31, 30, 19, 17])\n",
      "target_variable: tensor([[1441,   14,   14,  294,  193],\n",
      "        [  30,    6,  193,    6,   12],\n",
      "        [1440,  183,   15, 1335, 1069],\n",
      "        [  15,   12,    2,   54,   21],\n",
      "        [   2,  360,    0,  737, 1036],\n",
      "        [   0,   12,    0,   12,   12],\n",
      "        [   0,    4,    0,  232,  874],\n",
      "        [   0,    8,    0,    6,    6],\n",
      "        [   0, 2446,    0,    8, 1069],\n",
      "        [   0,   15,    0,    8,   54],\n",
      "        [   0,    2,    0,   15,   11],\n",
      "        [   0,    0,    0,    2,   11],\n",
      "        [   0,    0,    0,    0,    8],\n",
      "        [   0,    0,    0,    0,   15],\n",
      "        [   0,    0,    0,    0,    2]])\n",
      "mask: tensor([[ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True, False,  True,  True],\n",
      "        [False,  True, False,  True,  True],\n",
      "        [False,  True, False,  True,  True],\n",
      "        [False,  True, False,  True,  True],\n",
      "        [False,  True, False,  True,  True],\n",
      "        [False,  True, False,  True,  True],\n",
      "        [False,  True, False,  True,  True],\n",
      "        [False, False, False,  True,  True],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False, False,  True]])\n",
      "max_target_len: 15\n"
     ]
    }
   ],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "            # print(\"start test\")\n",
    "            encoder.eval()\n",
    "            decoder.eval()\n",
    "\n",
    "            searcher = GreedySearchDecoder(encoder, decoder)\n",
    "            train_bleu_score = evaluateTest(pairs, encoder, decoder, searcher, voc)\n",
    "            print(\"train bleu score:{}\".format(train_bleu_score))\n",
    "            test_bleu_score = evaluateTest(test_pairs, encoder, decoder, searcher, voc)\n",
    "            print(\"test bleu score:{}\".format(test_bleu_score))\n",
    "            encoder.train()\n",
    "            decoder.train()\n",
    "\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xa"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")\n",
    "\n",
    "def evaluateSentence(input_sentence, encoder, decoder, searcher, voc):\n",
    "    input_sentence = normalizeString(input_sentence)\n",
    "    output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "    # Format and print response sentence\n",
    "    new_output_words = []\n",
    "    for x in output_words:\n",
    "        if x == \"EOS\" or x == \"PAD\":\n",
    "            break\n",
    "        new_output_words.append(x)\n",
    "    return \" \".join(new_output_words)\n",
    "\n",
    "\n",
    "def get_bleu_result(candidate, reference):\n",
    "    candidate = \" \".join([candidate, candidate, candidate, candidate])\n",
    "    reference = \" \".join([reference, reference, reference, reference])\n",
    "    reference = [[item for item in reference.split(\" \")]]\n",
    "    candidate = [item for item in candidate.split(\" \")]\n",
    "    score = sentence_bleu(reference, candidate)\n",
    "    # print(reference, candidate)\n",
    "    return score\n",
    "\n",
    "def evaluateTest(pairs, encoder, decoder, searcher, voc):\n",
    "    scores = []\n",
    "    new_pair = [random.choice(pairs) for _ in range(20)]\n",
    "    for (input_sentence, output_sentence) in new_pair:\n",
    "        try:\n",
    "            output_words = evaluateSentence(input_sentence, encoder, decoder, searcher, voc)\n",
    "            print(\"IN:\\t{}\".format(input_sentence))\n",
    "            print(\"PRED:\\t{}\".format(output_words))\n",
    "            print(\"REAL:\\t{}\".format(output_sentence))\n",
    "            bleu_score = get_bleu_result(output_words, output_sentence)\n",
    "            scores.append(bleu_score)\n",
    "        except:\n",
    "            pass\n",
    "    return np.mean(scores)\n",
    "    # return scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sy\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\sy\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\sy\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.821831989445342e-231"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "references = [[['a'], ['this', 'is' 'test']]]\n",
    "candidates = [['a']]\n",
    "score = corpus_bleu(references, candidates)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 4000\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 500; Percent complete: 12.5%; Average loss: 3.8495\n",
      "IN:\tprivate double maxDistinctValuesByLowHigh ( VariableStatsEstimate variableStats , Type type ) { if ( variableStats . statisticRange ( ) . length ( ) == 0.0 ) { return 1 ; } if ( ! isDiscrete ( type ) ) { return NaN ; } double length = variableStats . getHighValue ( ) - variableStats . getLowValue ( ) ; if ( isNaN ( length ) ) { return NaN ; } if ( type instanceof DecimalType ) {\n",
      "PRED:\tif ( ! ( java . class ) {\n",
      "REAL:\tlength *= pow ( 10 , ( ( DecimalType ) type ) . getScale ( ) ) ;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sy\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\sy\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\sy\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN:\tprivate int readableBytes ( ) { int readable = 0 ; for ( WritableBuffer writableBuffer : bufferList ) { readable += writableBuffer . readableBytes ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic int hashCode ( ) { if ( memoizedHashCode != 0 ) { return memoizedHashCode ; }\n",
      "PRED:\t}\n",
      "REAL:\tint hash = 41 ;\n",
      "IN:\tpublic PluginConsole ( String pluginName ) { this . setIconImages ( Resources . iconList ) ; setTitle ( \" \" + pluginName ) ; setSize ( new Dimension ( 542 , 316 ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tgetContentPane ( ) . add ( scrollPane , BorderLayout . CENTER ) ;\n",
      "IN:\tprivate File getLogFile ( @ NonNull String folderName , @ NonNull String fileName ) { checkNotNull ( folderName ) ; checkNotNull ( fileName ) ; File folder = new File ( folderName ) ; if ( ! folder . exists ( ) ) { folder . mkdirs ( ) ; }\n",
      "PRED:\t}\n",
      "REAL:\tint newFileCount = 0 ;\n",
      "IN:\tpublic void createTest ( ) { for ( int i = 0 ;\n",
      "PRED:\t}\n",
      "REAL:\ti < 1 ;\n",
      "IN:\tpublic void testFromCpuInfoI7 ( ) throws IOException { final InputStream i7 = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( \" \" ) ; VanillaCpuLayout vcl = VanillaCpuLayout . fromCpuInfo ( i7 ) ;\n",
      "PRED:\t}\n",
      "REAL:\tassertEquals ( \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" , vcl . toString ( ) ) ;\n",
      "IN:\tpublic java . lang . String getName ( ) { java . lang . Object ref = name_ ; if ( ! ( ref instanceof java . lang . String ) ) {\n",
      "PRED:\treturn new ArrayList ( ) ;\n",
      "REAL:\tcom . google . protobuf . ByteString bs = ( com . google . protobuf . ByteString ) ref ;\n",
      "IN:\tpublic void run ( ) { ZooKeeperALiveCheckerJob job = new ZooKeeperALiveCheckerJob ( ) ; for ( String server : serverList ) {\n",
      "PRED:\tif ( ! ( ( ( ( java . class ) ) {\n",
      "REAL:\tjob . checkAliveNoAlarm ( server ) ;\n",
      "IN:\tprotected void call ( DocumentEvent e ) { try { changedPatternCallback . accept ( e . getDocument ( ) . getText ( 0 , e . getDocument ( ) . getLength ( ) ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic com . google . protobuf . ByteString getContentEncodingBytes ( ) { java . lang . Object ref = contentEncoding_ ;\n",
      "PRED:\t}\n",
      "REAL:\tif ( ref instanceof String ) {\n",
      "IN:\tpublic boolean tunnelFailed ( ) { boolean rv = super . tunnelFailed ( ) ; if ( ! rv ) {\n",
      "PRED:\tif ( ! ( java . class ) {\n",
      "REAL:\t_pool . tunnelFailed ( this ) ;\n",
      "IN:\tpublic Iterator < V > iterator ( ) { return new Iterator < V > ( ) { final PrimitiveIterator iter = new PrimitiveIterator ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\t@ Override public boolean hasNext ( ) {\n",
      "IN:\tpublic void evaluate ( ) throws Throwable { runWithAssignment ( Assignments . allUnassigned ( testMethod . getMethod ( ) , getTestClass ( ) ) ) ; boolean hasTheoryAnnotation = testMethod . getAnnotation ( Theory . class ) != null ; if ( successes == 0 && hasTheoryAnnotation ) {\n",
      "PRED:\t}\n",
      "REAL:\tAssert . fail ( \" \" + fInvalidParameters ) ;\n",
      "IN:\tprotected void onCreate ( Bundle icicle , @ NonNull MasterSecret masterSecret ) { this . masterSecret = masterSecret ;\n",
      "PRED:\t}\n",
      "REAL:\tgetSupportActionBar ( ) . setDisplayOptions ( ActionBar . DISPLAY_SHOW_HOME | ActionBar . DISPLAY_SHOW_TITLE ) ;\n",
      "IN:\tpublic void onPageFinished ( WebView view , String url ) { if ( mClient != null ) { mClient . onPageFinished ( view , url ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void realmResults_emittedChangesetOnUpdate ( ) { final AtomicInteger subscriberCalled = new AtomicInteger ( 0 ) ; Realm realm = looperThread . getRealm ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\trealm . beginTransaction ( ) ;\n",
      "IN:\tpublic Handlebars getHandlebars ( ) {\n",
      "PRED:\tif ( ! ( ( java . class ) {\n",
      "REAL:\tif ( handlebars == null ) {\n",
      "IN:\tpublic Builder setObject ( io . kubernetes . client . proto . Runtime . RawExtension value ) { if ( objectBuilder_ == null ) { if ( value == null ) {\n",
      "PRED:\t}\n",
      "REAL:\tthrow new NullPointerException ( ) ;\n",
      "IN:\tpublic static void acceptParameter ( DexAnnotationNode ann , int index , MethodVisitor v ) { AnnotationVisitor av = v . visitParameterAnnotation ( index , ann . type , ann . visibility != Visibility . BUILD ) ; if ( av != null ) { accept ( ann . items , av ) ; av . visitEnd ( ) ; }\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "train bleu score:0.20974740066016184\n",
      "IN:\tpublic static void main ( String [ ] args ) throws Exception { new Runner ( new OptionsBuilder ( ) . include ( SizeBenchmark . class . getSimpleName ( ) ) . forks ( 1 ) . warmupIterations ( 5 ) . measurementIterations ( 5 ) . build ( ) ) . run ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic static < T > T proxy ( T target , Aspect aspect ) { return ProxyFactory . createProxy ( target , aspect ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprivate void loadDefaultConnectionFile ( ) throws IOException {\n",
      "PRED:\tif ( ! ( ( ( java . class ) ) {\n",
      "REAL:\tif ( defaultConnectionFile . exists ( ) ) {\n",
      "IN:\tpublic static Builder newBuilder ( io . kubernetes . client . proto . V1beta1Admission . AdmissionReview prototype ) {\n",
      "PRED:\tif ( ! ( java . lang . String ) {\n",
      "REAL:\treturn DEFAULT_INSTANCE . toBuilder ( ) . mergeFrom ( prototype ) ;\n",
      "IN:\tpublic SearchInConstantPoolsView ( API api , JFrame mainFrame , BiConsumer < String , Integer > changedPatternCallback , TriConsumer < URI , String , Integer > selectedTypeCallback ) { this . api = api ;\n",
      "PRED:\tif ( ! ( ! int . length ( ) ) {\n",
      "REAL:\tSwingUtil . invokeLater ( ( ) -> {\n",
      "IN:\tpublic void nullAnnotationsAddition ( ) { try { MethodSpec . methodBuilder ( \" \" ) . addAnnotations ( null ) ; fail ( ) ; }\n",
      "PRED:\t}\n",
      "REAL:\tcatch ( IllegalArgumentException expected ) {\n",
      "IN:\tpublic static Action newAction ( String name , boolean enable , String shortDescription , ActionListener listener ) { Action action = newAction ( name , enable , listener ) ; action . putValue ( Action . SHORT_DESCRIPTION , shortDescription ) ; return action ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic String elapsedTimeAsString ( long runTime ) {\n",
      "PRED:\tif ( ( ( ( ( ( ( ( ( ( ( ( ( java . length ) ) {\n",
      "REAL:\treturn NumberFormat . getInstance ( ) . format ( ( double ) runTime / 1000 ) ;\n",
      "IN:\tprotected @ NonNull SQLiteStatement setBindings ( @ NonNull SQLiteStatement stmt , @ NonNull final Recurrence recurrence ) {\n",
      "PRED:\tif ( ! ( java . class ) {\n",
      "REAL:\tstmt . clearBindings ( ) ;\n",
      "IN:\tprivate GoogleDefaultChannelBuilder ( String target ) { delegate = NettyChannelBuilder . forTarget ( target ) ; SslContext sslContext ; try { sslContext = GrpcSslContexts . forClient ( ) . build ( ) ; }\n",
      "PRED:\t}\n",
      "REAL:\tcatch ( SSLException e ) {\n",
      "IN:\tpublic Class < ? > nodeToClass ( ClassNode node ) { if ( super . findLoadedClass ( node . name . replace ( \" \" , \" \" ) ) != null ) return findLoadedClass ( node . name . replace ( \" \" , \" \" ) ) ; ClassWriter cw = new ClassWriter ( ClassWriter . COMPUTE_MAXS ) ; try { node . accept ( cw ) ; } catch ( Exception e ) {\n",
      "PRED:\tif ( ! ( java . lang . String ) {\n",
      "REAL:\te . printStackTrace ( ) ;\n",
      "IN:\tpublic void writeTo ( com . google . protobuf . CodedOutputStream output ) throws java . io . IOException { if ( ( ( bitField0_ & 0x00000001 ) == 0x00000001 ) ) { output . writeMessage ( 1 , getMetadata ( ) ) ; } if ( ( ( bitField0_ & 0x00000002 ) == 0x00000002 ) ) { output . writeMessage ( 2 , getTemplate ( ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic MethodVisitor visitMethod ( int access , String name , String desc , String signature , String [ ] exceptions ) { if ( \" \" . equals ( name ) ) { constructorDeclarationSet . add ( this . name ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprivate static ArrayList < ParameterSignature > signatures ( Class < ? > [ ] parameterTypes , Annotation [ ] [ ] parameterAnnotations ) { ArrayList < ParameterSignature > sigs = new ArrayList < ParameterSignature > ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tfor ( int i = 0 ;\n",
      "IN:\tpublic void testAllInfoUnsynchronized ( ) throws Exception { DublinCoreSchema dc = metadata . createAndAddDublinCoreSchema ( ) ; AdobePDFSchema pdf = metadata . createAndAddAdobePDFSchema ( ) ; XMPBasicSchema xmp = metadata . createAndAddXMPBasicSchema ( ) ; dico . setTitle ( \" \" ) ;\n",
      "PRED:\t}\n",
      "REAL:\tdc . setTitle ( \" \" , \" \" ) ;\n",
      "IN:\tpublic void wildcardMirrorSuperType ( ) throws Exception { Types types = getTypes ( ) ; Elements elements = getElements ( ) ; TypeMirror string = elements . getTypeElement ( String . class . getName ( ) ) . asType ( ) ; WildcardType wildcard = types . getWildcardType ( null , string ) ;\n",
      "PRED:\t}\n",
      "REAL:\tTypeName type = TypeName . get ( wildcard ) ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN:\tpublic List < V > topologicalSort ( ) { Map < V , Integer > degree = inDegree ( ) ; Stack < V > zeroVertices = new Stack < > ( ) ; for ( V v : degree . keySet ( ) ) { if ( degree . get ( v ) == 0 ) { zeroVertices . push ( v ) ; } }\n",
      "PRED:\t}\n",
      "REAL:\tList < V > result = new ArrayList < > ( ) ;\n",
      "IN:\tpublic CsvTransactionsExporter ( ExportParams params , SQLiteDatabase db ) {\n",
      "PRED:\tif ( ! ( java . length ( ) ) {\n",
      "REAL:\tsuper ( params , db ) ;\n",
      "IN:\tprotected void run ( StructuredGraph graph ) { for ( Invoke invoke : graph . getInvokes ( ) ) { if ( invoke instanceof InvokeWithExceptionNode ) { InvokeWithExceptionNode invokeWithException = ( InvokeWithExceptionNode ) invoke ; ResolvedJavaMethod targetMethod = invokeWithException . callTarget ( ) . targetMethod ( ) ; if ( deoptimizeOnExceptionPredicate . test ( targetMethod ) ) { AbstractBeginNode exceptionEdge = invokeWithException . exceptionEdge ( ) ; FixedWithNextNode newNode = graph . add ( new SpeculativeExceptionAnchorNode ( DeoptimizationReason . TransferToInterpreter , DeoptimizationAction . InvalidateRecompile , targetMethod ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tgraph . addAfterFixed ( exceptionEdge , newNode ) ;\n",
      "IN:\tpublic void testStringCompatibility ( ) throws IOException { Path testFile = new Path ( Resources . getResource ( \" \" ) . getFile ( ) ) ; Configuration conf = new Configuration ( ) ; conf . setBoolean ( AvroReadSupport . AVRO_COMPATIBILITY , false ) ; ParquetReader < GenericRecord > reader = AvroParquetReader . builder ( new AvroReadSupport < GenericRecord > ( ) , testFile ) . withConf ( conf ) . build ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tGenericRecord r ;\n",
      "test bleu score:0.2635516688090768\n",
      "Iteration: 1000; Percent complete: 25.0%; Average loss: 2.8539\n",
      "IN:\tprotected void printDefects ( Enumeration < TestFailure > booBoos , int count , String type ) { if ( count == 0 ) return ; if ( count == 1 ) { getWriter ( ) . println ( \" \" + count + \" \" + type + \" \" ) ; } else { getWriter ( ) . println ( \" \" + count + \" \" + type + \" \" ) ; } for ( int i = 1 ; booBoos . hasMoreElements ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\ti ++ ) {\n",
      "IN:\tprotected final String createKnowledgeBaseName ( String storageName , String separator ) { return storageName + separator + getClass ( ) . getSimpleName ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic static void main ( String [ ] args ) { var numbers = new LinkedList < Integer > ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tfor ( int i = 0 ;\n",
      "IN:\tpublic void putIfAbsent_writerFails ( Map < Integer , Integer > map , CacheContext context ) { try { map . putIfAbsent ( context . absentKey ( ) , context . absentValue ( ) ) ; } finally { assertThat ( map , equalTo ( context . original ( ) ) ) ; }\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic static void assertEquals ( String message , Object expected , Object actual ) { Assert . assertEquals ( message , expected , actual ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic boolean intersects ( double rx , double ry , double rw , double rh ) { return intersects ( new Rectangle2D . Double ( rx , ry , rw , rh ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprivate MaterialViewPagerSettings ( Parcel in ) { this . headerLayoutId = in . readInt ( ) ; this . pagerTitleStripId = in . readInt ( ) ; this . viewpagerId = in . readInt ( ) ; this . logoLayoutId = in . readInt ( ) ; this . logoMarginTop = in . readInt ( ) ; this . headerAdditionalHeight = in . readInt ( ) ; this . headerHeight = in . readInt ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tthis . headerHeightPx = in . readInt ( ) ;\n",
      "IN:\tpublic byte [ ] deserialize ( InputStream inputStream ) throws IOException { byte [ ] buffer = new byte [ this . maxMessageSize ] ; int n = 0 ; int bite ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( \" \" + inputStream . available ( ) ) ; } while ( true ) {\n",
      "PRED:\treturn new File ( \" \" ) ;\n",
      "REAL:\tbite = inputStream . read ( ) ;\n",
      "IN:\tpublic void unzip ( final Path zipFile ) { try { String destinationPath = this . baseDirPath ; final Path destDir = Files . createDirectories ( FileSystems . getDefault ( ) . getPath ( destinationPath ) ) ; if ( notExists ( destDir ) ) { createDirectories ( destDir ) ; } try ( FileSystem zipFileSystem = FileSystems . newFileSystem ( zipFile , null ) ) { final Path root = zipFileSystem . getRootDirectories ( ) . iterator ( ) . next ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\twalkFileTree ( root , new SimpleFileVisitor < Path > ( ) {\n",
      "IN:\tpublic int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = ( prime * result ) + ( ( obfuscatedName == null ) ? 0 : obfuscatedName . hashCode ( ) ) ; result = ( prime * result ) + ( ( refactoredName == null ) ? 0 : refactoredName . hashCode ( ) ) ; return result ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprivate void refreshAccountsList ( ) { try { mActivityRule . runOnUiThread ( new Runnable ( ) { @ Override public void run ( ) { Fragment fragment = mAccountsActivity . getCurrentAccountListFragment ( ) ; ( ( AccountsListFragment ) fragment ) . refresh ( ) ; } }\n",
      "PRED:\t}\n",
      "REAL:\t) ;\n",
      "IN:\tprotected Collection < Field > getDataPointsFields ( ParameterSignature sig ) { Collection < Field > fields = super . getDataPointsFields ( sig ) ; String requestedName = sig . getAnnotation ( FromDataPoints . class ) . value ( ) ; List < Field > fieldsWithMatchingNames = new ArrayList < Field > ( ) ; for ( Field field : fields ) { String [ ] fieldNames = field . getAnnotation ( DataPoints . class ) . value ( ) ; if ( Arrays . asList ( fieldNames ) . contains ( requestedName ) ) {\n",
      "PRED:\tif ( ! String . length ( ) ) {\n",
      "REAL:\tfieldsWithMatchingNames . add ( field ) ;\n",
      "IN:\tpublic Future < Void > kill ( ) { final Promise < Void > future = new Promise < Void > ( ) ; next . getDispatchQueue ( ) . execute ( new Task ( ) { public void run ( ) {\n",
      "PRED:\tif ( ! StringUtils . isEmpty ( ) ) {\n",
      "REAL:\tnext . kill ( future ) ;\n",
      "IN:\tpublic Response getZNodeListAsOctet ( @ PathParam ( \" \" ) String path ) throws InterruptedException , KeeperException { ensurePathNotNull ( path ) ; Stat stat = new Stat ( ) ; byte [ ] data = zk . getData ( path , false , stat ) ;\n",
      "PRED:\t}\n",
      "REAL:\tif ( data == null ) {\n",
      "IN:\tpublic static byte [ ] toByteArray ( InputStream input ) throws IOException { ByteArrayOutputStream os = new ByteArrayOutputStream ( ) ; byte [ ] buf = new byte [ 1024 ] ; for ( int n = input . read ( buf ) ; n != - 1 ;\n",
      "PRED:\t}\n",
      "REAL:\tn = input . read ( buf ) ) {\n",
      "IN:\tpublic void example4 ( MessageConsumer < String > consumer ) { consumer . unregister ( res -> { if ( res . succeeded ( ) ) {\n",
      "PRED:\t}\n",
      "REAL:\tSystem . out . println ( \" \" ) ;\n",
      "IN:\tpublic MQTTFrame apply ( ) throws IOException { int limit = readBuffer . position ( ) ; if ( ( limit - readStart ) < length ) { readEnd = limit ;\n",
      "PRED:\t}\n",
      "REAL:\treturn null ;\n",
      "IN:\tpublic Boolean extractResource ( InputStream resource ) { synchronized ( mLock ) { if ( ! isDirectory ( ) ) { try { FileWriter writer = getFileWriter ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tif ( writer != null ) {\n",
      "IN:\tpublic static io . kubernetes . client . proto . Runtime . Unknown parseFrom ( com . google . protobuf . ByteString data , com . google . protobuf . ExtensionRegistryLite extensionRegistry ) throws com . google . protobuf . InvalidProtocolBufferException { return PARSER . parseFrom ( data , extensionRegistry ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic Future < Void > kill ( ) { final Promise < Void > future = new Promise < Void > ( ) ;\n",
      "PRED:\tif ( ! StringUtils . isEmpty ( ) ) {\n",
      "REAL:\tnext . getDispatchQueue ( ) . execute ( new Task ( ) {\n",
      "train bleu score:0.3\n",
      "IN:\tpublic StormcallersBoon ( UUID ownerId , CardSetInfo setInfo ) { super ( ownerId , setInfo , new CardType [ ] {\n",
      "PRED:\t}\n",
      "REAL:\tCardType . ENCHANTMENT }\n",
      "IN:\tpublic BindingImpl < T > withScoping ( Scoping scoping ) {\n",
      "PRED:\treturn new File ( \" \" ) ;\n",
      "REAL:\treturn new InstanceBindingImpl < T > ( getSource ( ) , getKey ( ) , scoping , injectionPoints , instance ) ;\n",
      "IN:\tpublic boolean onQueryTextChange ( String newText ) { if ( filter == null ) return true ; if ( TextUtils . isEmpty ( newText ) ) { filter . filter ( null ) ; }\n",
      "PRED:\treturn false ;\n",
      "REAL:\telse {\n",
      "IN:\tpublic void writeTo ( com . google . protobuf . CodedOutputStream output ) throws java . io . IOException { if ( ( ( bitField0_ & 0x00000001 ) == 0x00000001 ) ) {\n",
      "PRED:\t}\n",
      "REAL:\toutput . writeMessage ( 1 , getMetadata ( ) ) ;\n",
      "IN:\tpublic I extra ( String name , Parcelable [ ] value ) { intent . putExtra ( name , value ) ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED:\t}\n",
      "REAL:\treturn ( I ) this ;\n",
      "IN:\tpublic BlogDetailVO getBlogDetail ( Long id ) { Blog blog = blogMapper . selectByPrimaryKey ( id ) ; BlogDetailVO blogDetailVO = getBlogDetailVO ( blog ) ; if ( blogDetailVO != null ) {\n",
      "PRED:\tif ( ! StringUtils . equals ( \" \" ) ) {\n",
      "REAL:\treturn blogDetailVO ;\n",
      "IN:\tpublic Builder addEnv ( int index , io . kubernetes . client . proto . V1 . EnvVar . Builder builderForValue ) { if ( envBuilder_ == null ) {\n",
      "PRED:\treturn this ;\n",
      "REAL:\tensureEnvIsMutable ( ) ;\n",
      "IN:\tpublic EqualsBuilder append ( final int lhs , final int rhs ) { if ( isEquals == false ) { return this ; } isEquals = ( lhs == rhs ) ; return this ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic static int compareUnsigned ( long leftRawLow , long leftRawHigh , long rightRawLow , long rightRawHigh ) { if ( leftRawHigh != rightRawHigh ) { return Long . compareUnsigned ( leftRawHigh , rightRawHigh ) ; } if ( leftRawLow != rightRawLow ) { return Long . compareUnsigned ( leftRawLow , rightRawLow ) ; } return 0 ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic Builder addAnnotation ( AnnotationSpec annotationSpec ) { checkNotNull ( annotationSpec , \" \" ) ; this . annotations . add ( annotationSpec ) ;\n",
      "PRED:\t}\n",
      "REAL:\treturn this ;\n",
      "IN:\tprotected void onPostExecute ( Void result ) { super . onPostExecute ( result ) ; if ( actionMode != null ) { actionMode . finish ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tactionMode = null ;\n",
      "IN:\tprotected void checkGrammarSemanticsWarning ( ErrorQueue equeue , GrammarSemanticsMessage expectedMessage ) throws Exception { ANTLRMessage foundMsg = null ; for ( int i = 0 ; i < equeue . warnings . size ( ) ; i ++ ) { ANTLRMessage m = equeue . warnings . get ( i ) ; if ( m . getErrorType ( ) == expectedMessage . getErrorType ( ) ) { foundMsg = m ; } } assertNotNull ( \" \" + expectedMessage . getErrorType ( ) + \" \" , foundMsg ) ;\n",
      "PRED:\t}\n",
      "REAL:\tassertTrue ( \" \" , foundMsg instanceof GrammarSemanticsMessage ) ;\n",
      "IN:\tpublic Builder setMetadata ( io . kubernetes . client . proto . Meta . ListMeta value ) { if ( metadataBuilder_ == null ) { if ( value == null ) {\n",
      "PRED:\treturn this ;\n",
      "REAL:\tthrow new NullPointerException ( ) ;\n",
      "IN:\tpublic void emitCode ( CompilationResultBuilder crb , AMD64MacroAssembler masm ) { if ( isRegister ( result ) ) { if ( selector == 0 ) { VMOVD . emitReverse ( masm , XMM , asRegister ( result ) , asRegister ( vector ) ) ; } else { VPEXTRD . emit ( masm , XMM , asRegister ( result ) , asRegister ( vector ) , selector ) ; } } else {\n",
      "PRED:\t}\n",
      "REAL:\tassert isStackSlot ( result ) ;\n",
      "IN:\tpublic void testPreProcess ( ) throws Exception { StemmingPreprocessor preprocessor = new StemmingPreprocessor ( ) ; String test = \" \" ; String output = preprocessor . preProcess ( test ) ; System . out . println ( \" \" + output ) ;\n",
      "PRED:\t}\n",
      "REAL:\tassertEquals ( \" \" , output ) ;\n",
      "IN:\tpublic String getFirstSourceText ( ) { if ( getSourceTexts ( ) != null && getSourceTexts ( ) . size ( ) > 0 ) { return getSourceTexts ( ) . get ( 0 ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic io . kubernetes . client . proto . Meta . ObjectMeta getMetadata ( ) { if ( metadataBuilder_ == null ) { return metadata_ == null ? io . kubernetes . client . proto . Meta . ObjectMeta . getDefaultInstance ( ) : metadata_ ; } else { return metadataBuilder_ . getMessage ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic Builder clearItems ( ) { if ( itemsBuilder_ == null ) { items_ = java . util . Collections . emptyList ( ) ; bitField0_ = ( bitField0_ & ~ 0x00000002 ) ; onChanged ( ) ; } else { itemsBuilder_ . clear ( ) ; } return this ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "test bleu score:0.2802904059035438\n",
      "Iteration: 1500; Percent complete: 37.5%; Average loss: 2.5299\n",
      "IN:\tprotected LoginHelper ( LoginBuilder loginBuilder ) { loginBuilder . validateAndSetValues ( ) ; this . username = loginBuilder . username ; this . password = loginBuilder . password ; this . connectionKey = loginBuilder . connectionKey ;\n",
      "PRED:\tthis . printStream = new MageInt ( ) ;\n",
      "REAL:\tthis . tcpServerAddress = loginBuilder . tcpServerAddress ;\n",
      "IN:\tpublic void deviceSearchResponse ( SSDPPacket ssdpPacket ) { String ssdpST = ssdpPacket . getST ( ) ; if ( ssdpST == null ) return ; boolean isRootDevice = isRootDevice ( ) ; String devUSN = getUDN ( ) ; if ( isRootDevice == true ) devUSN += \" \" + USN . ROOTDEVICE ; if ( ST . isAllDevice ( ssdpST ) == true ) { String devNT = getNotifyDeviceNT ( ) ; int repeatCnt = ( isRootDevice == true ) ? 3 : 2 ;\n",
      "PRED:\t}\n",
      "REAL:\tfor ( int n = 0 ;\n",
      "IN:\tpublic void validateEventParserWithEventTypes ( ) { Object adapter = context . getBean ( \" \" ) ; assertThat ( adapter ) . isNotNull ( ) ; assertThat ( adapter instanceof ApplicationEventListeningMessageProducer ) . isTrue ( ) ; DirectFieldAccessor adapterAccessor = new DirectFieldAccessor ( adapter ) ; assertThat ( adapterAccessor . getPropertyValue ( \" \" ) ) . isEqualTo ( context . getBean ( \" \" ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tSet < ResolvableType > eventTypes = ( Set < ResolvableType > ) adapterAccessor . getPropertyValue ( \" \" ) ;\n",
      "IN:\tprivate AbortProcessingException abortWithError ( Element e , String msg , Object ... msgParams ) { reportError ( e , msg , msgParams ) ;\n",
      "PRED:\t}\n",
      "REAL:\treturn new AbortProcessingException ( ) ;\n",
      "IN:\tpublic static SigningPrivateKey fromJavaKey ( ECPrivateKey pk , SigType type ) throws GeneralSecurityException { BigInteger s = pk . getS ( ) ; int len = type . getPrivkeyLen ( ) ; byte [ ] bs = rectify ( s , len ) ;\n",
      "PRED:\t}\n",
      "REAL:\treturn new SigningPrivateKey ( type , bs ) ;\n",
      "IN:\tpublic io . kubernetes . client . proto . Meta . GroupVersionResourceOrBuilder getResourceOrBuilder ( ) {\n",
      "PRED:\treturn this . typeMeta_ . getMessageOrBuilder ( ) ;\n",
      "REAL:\tif ( resourceBuilder_ != null ) {\n",
      "IN:\tprivate BoundObjectReference ( com . google . protobuf . CodedInputStream input , com . google . protobuf . ExtensionRegistryLite extensionRegistry ) throws com . google . protobuf . InvalidProtocolBufferException { this ( ) ;\n",
      "PRED:\tif ( value == null ) {\n",
      "REAL:\tif ( extensionRegistry == null ) {\n",
      "IN:\tpublic void testCheckTransfer ( ) throws Exception { when ( mockClient . transferOperations ( ) ) . thenReturn ( mockOps ) ; when ( mockOps . list ( Matchers . anyString ( ) ) ) . thenReturn ( mockList ) ; when ( mockList . setFilter ( Matchers . anyString ( ) ) ) . thenReturn ( mockList ) ;\n",
      "PRED:\t}\n",
      "REAL:\tRequestChecker . checkTransfer ( mockClient , \" \" , \" \" ) ;\n",
      "IN:\tpublic void convertFileToResource ( ) throws IOException { Document metadata = new Document ( \" \" , \" \" ) ; ObjectId reference = operations . store ( resource . getInputStream ( ) , \" \" , metadata ) ; GridFSFile file = operations . findOne ( query ( whereMetaData ( \" \" ) . is ( \" \" ) ) ) ; GridFsResource result = operations . getResource ( file ) ; assertThat ( result . contentLength ( ) ) . isEqualTo ( resource . contentLength ( ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tassertThat ( ( ( BsonObjectId ) result . getId ( ) ) . getValue ( ) ) . isEqualTo ( reference ) ;\n",
      "IN:\tpublic Builder setUserInfo ( io . kubernetes . client . proto . V1Authentication . UserInfo value ) { if ( userInfoBuilder_ == null ) { if ( value == null ) {\n",
      "PRED:\treturn this ;\n",
      "REAL:\tthrow new NullPointerException ( ) ;\n",
      "IN:\tpublic Service getSubscriberService ( String uuid ) { ServiceList serviceList = getServiceList ( ) ;\n",
      "PRED:\tString String = \" \" ;\n",
      "REAL:\tint serviceCnt = serviceList . size ( ) ;\n",
      "IN:\tprivate static Constructor < WritableRaster > getFactoryMethod ( ) { try { Class < ? > cls = Class . forName ( \" \" ) ;\n",
      "PRED:\tif ( ! e . equals ( \" \" ) ) {\n",
      "REAL:\tif ( Modifier . isAbstract ( cls . getModifiers ( ) ) ) {\n",
      "IN:\tpublic io . kubernetes . client . proto . V1Authentication . TokenReviewSpec build ( ) { io . kubernetes . client . proto . V1Authentication . TokenReviewSpec result = buildPartial ( ) ; if ( ! result . isInitialized ( ) ) { throw newUninitializedMessageException ( result ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprotected void onPostExecute ( Long resultThread ) { if ( resultThread > - 1 ) { Intent intent = new Intent ( GroupCreateActivity . this , ConversationActivity . class ) ; intent . putExtra ( ConversationActivity . THREAD_ID_EXTRA , resultThread . longValue ( ) ) ;\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000002 ) == 0x00000002 ) ) {\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL:\tintent . putExtra ( ConversationActivity . DISTRIBUTION_TYPE_EXTRA , ThreadDatabase . DistributionTypes . DEFAULT ) ;\n",
      "IN:\tpublic Builder clearActive ( ) { if ( activeBuilder_ == null ) { active_ = java . util . Collections . emptyList ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tbitField0_ = ( bitField0_ & ~ 0x00000001 ) ;\n",
      "IN:\tpublic void addBindValues ( SpiExpressionRequest request ) { if ( value != null ) { request . addBindValue ( value ) ; } if ( upperValue != null ) { request . addBindValue ( upperValue ) ; }\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void rollback ( Throwable e ) throws PersistenceException { try { current . rollback ( e ) ; } finally { clearScope ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void testTrainAndValidateMultinomialNaiveBayes ( ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ ) {\n",
      "REAL:\tlogger . info ( \" \" ) ;\n",
      "IN:\tpublic synchronized void onException ( Event event ) { Session session = getSession ( ) ; String reconnectKey = ( String ) session . getAttribute ( Config . RECONNECT_KEY ) ; if ( null != reconnectKey ) { if ( isReconnecting ) { return ; } else { isReconnecting = true ; }\n",
      "PRED:\t}\n",
      "REAL:\tsession . setWriteable ( false ) ;\n",
      "IN:\tpublic synchronized void introduced ( byte bobIP [ ] , int bobPort ) { if ( _currentState != OutboundState . OB_STATE_PENDING_INTRO ) return ; _nextSend = _context . clock ( ) . now ( ) + WAIT_FOR_HOLE_PUNCH_DELAY ; _currentState = OutboundState . OB_STATE_INTRODUCED ; if ( _claimedAddress != null && bobPort == _bobPort && DataHelper . eq ( bobIP , _bobIP ) ) { _remoteHostId = _claimedAddress ; } else { _bobIP = bobIP ; _bobPort = bobPort ; _remoteHostId = new RemoteHostId ( bobIP , bobPort ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "train bleu score:0.2414894254091408\n",
      "IN:\tpublic FieldVisitor visitField ( int access , String name , String descriptor , String signature , Object value ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ ) == 0 ) ) {\n",
      "REAL:\tif ( ( access & ( Opcodes . ACC_SYNTHETIC | Opcodes . ACC_ENUM ) ) == 0 ) {\n",
      "IN:\tprotected String formatWithNullDetection ( MessageFormat mf , Object [ ] args ) { String message = mf . format ( args ) ; if ( \" \" . equals ( message ) ) { return null ; }\n",
      "PRED:\t}\n",
      "REAL:\telse {\n",
      "IN:\tpublic void innerClassInGenericType ( ) throws Exception { Method genericStringInner = getClass ( ) . getDeclaredMethod ( \" \" ) ; TypeName . get ( genericStringInner . getReturnType ( ) ) ; TypeName genericTypeName = TypeName . get ( genericStringInner . getGenericReturnType ( ) ) ;\n",
      "PRED:\tassertThat ( methodSpec . get ( ) ) . isEqualTo ( \" \" ) ;\n",
      "REAL:\tassertNotEquals ( TypeName . get ( genericStringInner . getGenericReturnType ( ) ) , TypeName . get ( getClass ( ) . getDeclaredMethod ( \" \" ) . getGenericReturnType ( ) ) ) ;\n",
      "IN:\tpublic Builder clear ( ) { super . clear ( ) ; if ( metadataBuilder_ == null ) { metadata_ = null ; } else { metadataBuilder_ . clear ( ) ; } bitField0_ = ( bitField0_ & ~ 0x00000001 ) ;\n",
      "PRED:\t}\n",
      "REAL:\tif ( itemsBuilder_ == null ) {\n",
      "IN:\tpublic boolean remove ( Object o ) {\n",
      "PRED:\treturn this . equals ( this . getClass ( ) ) ;\n",
      "REAL:\tonContentsChanged ( ) ;\n",
      "IN:\tprivate boolean shouldRead ( ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000002 ) == 0 ) ) {\n",
      "REAL:\tDatabaseEntry data = get ( _key , false ) ;\n",
      "IN:\tpublic static long addWithOverflow ( Slice left , Slice right , Slice result ) { boolean leftNegative = isNegative ( left ) ; boolean rightNegative = isNegative ( right ) ; long overflow = 0 ; if ( leftNegative == rightNegative ) { overflow = addUnsignedReturnOverflow ( left , right , result , leftNegative ) ; if ( leftNegative ) { overflow = - overflow ; }\n",
      "PRED:\treturn this ;\n",
      "REAL:\t}\n",
      "IN:\tpublic BufferedOutputFile getDirectBuffer ( ) { if ( ! Platform . isWindows ( ) ) {\n",
      "PRED:\treturn this . visit ( ) ;\n",
      "REAL:\treturn null ;\n",
      "IN:\tpublic I flags ( int flags ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000002 ) == 0 ) ) {\n",
      "REAL:\tintent . setFlags ( flags ) ;\n",
      "IN:\tprotected PNGInfo ( int width , int height , ImageFormat format , long size , ColorModel colorModel , Metadata metadata , boolean applyExifOrientation , boolean imageIOSupport ) throws ParseException { super ( width , height , format , size , colorModel , metadata , applyExifOrientation , imageIOSupport ) ; colorType = ( ( PNGParseInfo ) parsedInfo ) . colorType ; interlaceMethod = ( ( PNGParseInfo ) parsedInfo ) . interlaceMethod ; hasTransparencyChunk = ( ( PNGParseInfo ) parsedInfo ) . hasTransparencyChunk ; isModifiedBitDepth = ( ( PNGParseInfo ) parsedInfo ) . isModifiedBitDepth ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic static String toString ( byte [ ] bytes , int offset , int length ) { StringBuffer buf = new StringBuffer ( ) ; for ( int i = 0 ; i < length ; i ++ ) { appendHexChar ( buf , bytes [ offset + i ] ) ; buf . append ( \" \" ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic boolean accept ( File pathname ) {\n",
      "PRED:\treturn this . equals ( this . getClass ( ) ) ;\n",
      "REAL:\treturn pathname . getName ( ) . endsWith ( filesEndingWith ) ;\n",
      "IN:\tprivate static AppBarLayout . LayoutParams getLayoutParams ( View v ) { initialize ( ) ; AppBarLayout . LayoutParams result = null ; ViewGroup . LayoutParams layoutParams = v . getLayoutParams ( ) ; if ( null != layoutParams && layoutParams instanceof AppBarLayout . LayoutParams ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000002 ) == 0x00000002 ) ) {\n",
      "REAL:\tresult = ( AppBarLayout . LayoutParams ) layoutParams ;\n",
      "IN:\tpublic Builder setActive ( int index , io . kubernetes . client . proto . V1 . ObjectReference . Builder builderForValue ) { if ( activeBuilder_ == null ) { ensureActiveIsMutable ( ) ; active_ . set ( index , builderForValue . build ( ) ) ; onChanged ( ) ; } else {\n",
      "PRED:\treturn this ;\n",
      "REAL:\tactiveBuilder_ . setMessage ( index , builderForValue . build ( ) ) ;\n",
      "IN:\tpublic io . kubernetes . client . proto . V1alpha1Admission . AdmissionReview build ( ) { io . kubernetes . client . proto . V1alpha1Admission . AdmissionReview result = buildPartial ( ) ;\n",
      "PRED:\treturn this ;\n",
      "REAL:\tif ( ! result . isInitialized ( ) ) {\n",
      "IN:\tpublic boolean equals ( final java . lang . Object obj ) { if ( obj == this ) { return true ; }\n",
      "PRED:\treturn this ;\n",
      "REAL:\tif ( ! ( obj instanceof io . kubernetes . client . proto . V1Authentication . BoundObjectReference ) ) {\n",
      "IN:\tprivate static final Object [ ] [ ] OBJECTS = new Object [ ] [ ] { { \" \" , \" \" } , { \" \" , \" \" } , { \" \" , \" \" } , { \" \" , \" \" } , { \" \" , \" \" } , { \" \" , \" \" } , { \" \" , \" \" } , { \" \" , \" \" } , { \" \" , \" \" } , { \" \" , \" \" }\n",
      "PRED:\t, {\n",
      "REAL:\t, {\n",
      "IN:\tprivate void send ( Request request ) { if ( failure != null ) { if ( request . cb != null ) { request . cb . onFailure ( failure ) ; } } else { if ( request . id != 0 ) { this . requests . put ( request . id , request ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic PlanNodeStatsEstimate ( @ JsonProperty ( \" \" ) double outputRowCount , @ JsonProperty ( \" \" ) Map < VariableReferenceExpression , VariableStatsEstimate > variableStatistics ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ ) == 0 ) ) {\n",
      "REAL:\tthis ( outputRowCount , HashTreePMap . from ( requireNonNull ( variableStatistics , \" \" ) ) ) ;\n",
      "test bleu score:0.22726503521999297\n",
      "Iteration: 2000; Percent complete: 50.0%; Average loss: 2.3262\n",
      "IN:\tpublic AttachedFile ( @ Nonnull InputStream content , @ Nonnull String fileName , long fileSize ) { try { this . fileName = FilenameUtils . getName ( fileName ) ; this . contentType = MediaType . byFile ( this . fileName ) ; String filenameStar = URLEncoder . encode ( this . fileName , CHARSET ) . replaceAll ( \" \" , \" \" ) ; if ( this . fileName . equals ( filenameStar ) ) { this . contentDisposition = String . format ( CONTENT_DISPOSITION , this . fileName ) ;\n",
      "PRED:\tthis . = ( key ) ;\n",
      "REAL:\t}\n",
      "IN:\tpublic byte [ ] readLineBytes ( ) { ensureFill ( ) ; int pos = count ; final byte [ ] buf = this . buf ;\n",
      "PRED:\tint i = 0 ;\n",
      "REAL:\twhile ( true ) {\n",
      "IN:\tpublic VariableStatsAssertion highValue ( double expected ) { assertEstimateEquals ( statistics . getHighValue ( ) , expected , \" \" ) ;\n",
      "PRED:\t}\n",
      "REAL:\treturn this ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN:\tpublic static void acceptMethod ( SmaliParser . SMethodContext ctx , String className , DexClassVisitor dexClassVisitor ) { Method method ; Token methodObj = ctx . methodObj ; if ( methodObj . getType ( ) == SmaliLexer . METHOD_FULL ) { method = Utils . parseMethodAndUnescape ( methodObj . getText ( ) ) ; } else { method = Utils . parseMethodAndUnescape ( className , methodObj . getText ( ) ) ; } int access = collectAccess ( ctx . sAccList ( ) ) ; boolean isStatic = 0 != ( access & DexConstants . ACC_STATIC ) ;\n",
      "PRED:\t}\n",
      "REAL:\tDexMethodVisitor dexMethodVisitor = dexClassVisitor . visitMethod ( access , method ) ;\n",
      "IN:\tpublic Config setOverride ( boolean value ) {\n",
      "PRED:\treturn this ;\n",
      "REAL:\tthis . override . setValue ( value ) ;\n",
      "IN:\tpublic int hashCode ( ) { return ID . hashCode ( ) + ( int ) ( pixel * 10 ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void entryIterator_writerFails ( Map < Integer , Integer > map , CacheContext context ) { try { Iterator < Entry < Integer , Integer > > i = map . entrySet ( ) . iterator ( ) ; i . next ( ) ; i . remove ( ) ; } finally { assertThat ( map , equalTo ( context . original ( ) ) ) ; }\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void setOnEventListener ( final V view , final Value value ) { view . setOnLongClickListener ( new View . OnLongClickListener ( ) { @ Override public boolean onLongClick ( View v ) {\n",
      "PRED:\t@ Override public void mousePressed ( ) {\n",
      "REAL:\ttrigger ( Attributes . View . OnLongClick , value , ( ProteusView ) view ) ;\n",
      "IN:\tpublic void example6 ( Vertx vertx ) { DatagramSocket socket = vertx . createDatagramSocket ( new DatagramSocketOptions ( ) ) ; socket . listen ( 1234 , \" \" , asyncResult -> {\n",
      "PRED:\tthis . sbCode . append ( \" \" ) ;\n",
      "REAL:\tif ( asyncResult . succeeded ( ) ) {\n",
      "IN:\tpublic String [ ] getReadablePropertyNames ( ) { if ( this . propertyNames == null ) { final List < String > names = new ArrayList < String > ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tPropertyDescriptor [ ] props = this . beanWrapper . getPropertyDescriptors ( ) ;\n",
      "IN:\tprotected String access_clz ( final int access ) { StringBuilder b = new StringBuilder ( ) ; if ( ( access & Opcodes . ACC_PUBLIC ) != 0 ) { b . append ( \" \" ) ; } if ( ( access & Opcodes . ACC_PRIVATE ) != 0 ) { b . append ( \" \" ) ; } if ( ( access & Opcodes . ACC_PROTECTED ) != 0 ) {\n",
      "PRED:\treturn ( ( int ) ( vignetteEnd ( ) ) . named ( fieldName ) ;\n",
      "REAL:\tb . append ( \" \" ) ;\n",
      "IN:\tpublic void setScaleType ( ScaleType scaleType ) { if ( scaleType == ScaleType . MATRIX ) { super . setScaleType ( scaleType ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic Indicator ( Config config ) { this . sketch = new PeriodicResetCountMin4 ( ConfigFactory . parseString ( \" \" ) . withFallback ( config ) ) ; IndicatorSettings settings = new IndicatorSettings ( config ) ; this . sample = 0 ;\n",
      "PRED:\tthis . this . this . this . this . this . new IllegalStateException ( \" \" ) ;\n",
      "REAL:\tthis . k = settings . k ( ) ;\n",
      "IN:\tpublic boolean matches ( Element root , Element element ) { List < org . jsoup . nodes . Attribute > values = element . attributes ( ) . asList ( ) ; for ( org . jsoup . nodes . Attribute attribute : values ) { if ( lowerCase ( attribute . getKey ( ) ) . startsWith ( keyPrefix ) ) return true ; } return false ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic StromkirkPatrol ( UUID ownerId , CardSetInfo setInfo ) { super ( ownerId , setInfo , new CardType [ ] {\n",
      "PRED:\tCardType . CREATURE }\n",
      "REAL:\tCardType . CREATURE }\n",
      "IN:\tpublic List < String > getValidField ( ) { return Arrays . stream ( this . getClass ( ) . getDeclaredFields ( ) ) . map ( field -> { try { if ( ! ObjectUtils . isEmpty ( field . get ( this ) ) ) { return field . getName ( ) ; } return null ; } catch ( IllegalAccessException e ) { } return null ; }\n",
      "PRED:\t}\n",
      "REAL:\t) . filter ( Objects :: nonNull ) . collect ( Collectors . toList ( ) ) ;\n",
      "IN:\tpublic void applyFix ( @ NotNull Project project , @ NotNull ProblemDescriptor descriptor ) { final PsiElement expression = descriptor . getPsiElement ( ) ; if ( expression instanceof MethodReference && ! project . isDisposed ( ) ) { final MethodReference assertion = ( MethodReference ) expression ; final String pattern = String . format ( \" \" , String . join ( \" \" , this . arguments ) ) ; final PsiElement donor = PhpPsiElementFactory . createFunctionReference ( project , pattern ) . getParameterList ( ) ; final PsiElement socket = assertion . getParameterList ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tif ( donor != null && socket != null ) {\n",
      "IN:\tprivate JobCondition ( com . google . protobuf . CodedInputStream input , com . google . protobuf . ExtensionRegistryLite extensionRegistry ) throws com . google . protobuf . InvalidProtocolBufferException { this ( ) ; if ( extensionRegistry == null ) { throw new java . lang . NullPointerException ( ) ; } int mutable_bitField0_ = 0 ; com . google . protobuf . UnknownFieldSet . Builder unknownFields = com . google . protobuf . UnknownFieldSet . newBuilder ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\ttry {\n",
      "IN:\tpublic Result list ( @ RequestParam Map < String , Object > params ) { if ( StringUtils . isEmpty ( params . get ( \" \" ) ) || StringUtils . isEmpty ( params . get ( \" \" ) ) ) { } PageQueryUtil pageUtil = new PageQueryUtil ( params ) ; return ResultGenerator . genSuccessResult ( linkService . getBlogLinkPage ( pageUtil ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprivate FossilLanguage ( ) { super ( \" \" , \" \" , \" \" , Icons . FOSSIL , new OuterFileFetcher [ ] {\n",
      "PRED:\t\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \"\n",
      "REAL:\tproject -> {\n",
      "train bleu score:0.3055729064583009\n",
      "IN:\tprivate void fixPositions ( JavadocAllocationExpression node ) { node . sourceEnd = sourceEnd ; node . sourceStart = sourceStart ; node . statementEnd = sourceEnd ; node . memberStart = sourceStart ; node . tagSourceEnd = sourceEnd ;\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000001 ) == 0 ) ) {\n",
      "REAL:\tnode . tagSourceStart = sourceStart ;\n",
      "IN:\tpublic void testForwardsGetMemorySegment ( ) { assertSame ( buffer . getMemorySegment ( ) , buffer . readOnlySlice ( ) . getMemorySegment ( ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tassertSame ( buffer . getMemorySegment ( ) , buffer . readOnlySlice ( 1 , 2 ) . getMemorySegment ( ) ) ;\n",
      "IN:\tprivate Signature signIt ( SimpleDataStructure hash , SigningPrivateKey signingKey ) { if ( ( signingKey == null ) || ( hash == null ) ) return null ; if ( signingKey . getType ( ) != SigType . DSA_SHA1 ) throw new IllegalArgumentException ( \" \" + signingKey . getType ( ) ) ; long start = _context . clock ( ) . now ( ) ; BigInteger k ;\n",
      "PRED:\t}\n",
      "REAL:\tboolean ok ;\n",
      "IN:\tprivate List < Pattern > getNonProxyHostPatterns ( @ Nullable List < String > nonProxyHosts ) { if ( nonProxyHosts == null ) { return Collections . emptyList ( ) ; } final List < Pattern > patterns = new ArrayList < > ( nonProxyHosts . size ( ) ) ; for ( String nonProxyHost : nonProxyHosts ) { patterns . add ( Pattern . compile ( WILDCARD . matcher ( nonProxyHost ) . replaceAll ( REGEX_WILDCARD ) ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void testCalculateConnectionPerSlot ( ) { Set < HostAndPort > jedisClusterNode = new HashSet < HostAndPort > ( ) ; jedisClusterNode . add ( new HostAndPort ( \" \" , 7379 ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tJedisCluster jc = new JedisCluster ( jedisClusterNode , DEFAULT_TIMEOUT , DEFAULT_TIMEOUT , DEFAULT_REDIRECTIONS , \" \" , DEFAULT_CONFIG ) ;\n",
      "IN:\tprivate final int readFullyAt ( byte [ ] buf , int off , int len , long pos ) throws IOException { synchronized ( zfile ) { zfile . seek ( pos ) ; int N = len ; while ( N > 0 ) { int n = Math . min ( BUF_SIZE , N ) ; zfile . readFully ( buf , off , n ) ;\n",
      "PRED:\t}\n",
      "REAL:\toff += n ;\n",
      "IN:\tpublic boolean matches ( final Method method , final String name ) {\n",
      "PRED:\tif ( this . path . equals ( path ) ) {\n",
      "REAL:\tboolean isStatic = isStatic ( method ) ;\n",
      "IN:\tpublic Builder clear ( ) { super . clear ( ) ; if ( metadataBuilder_ == null ) { metadata_ = null ; } else { metadataBuilder_ . clear ( ) ; } bitField0_ = ( bitField0_ & ~ 0x00000001 ) ; if ( specBuilder_ == null ) { spec_ = null ; } else { specBuilder_ . clear ( ) ; } bitField0_ = ( bitField0_ & ~ 0x00000002 ) ;\n",
      "PRED:\t}\n",
      "REAL:\treturn this ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN:\tprivate double C ( RealVector alphaVector ) { double Cvalue ; double sumAi = 0.0 ; double sumLogGammaAi = 0.0 ; int aLength = alphaVector . getDimension ( ) ; double tmp ; for ( int i = 0 ; i < aLength ; ++ i ) { tmp = alphaVector . getEntry ( i ) ; sumAi += tmp ; sumLogGammaAi += ContinuousDistributions . logGamma ( tmp ) ; } Cvalue = sumLogGammaAi - ContinuousDistributions . logGamma ( sumAi ) ; return Cvalue ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic LabelStmt map ( LabelStmt label ) { LabelStmt nTarget = labels . get ( label ) ; if ( nTarget == null ) { nTarget = Stmts . nLabel ( ) ;\n",
      "PRED:\treturn this ;\n",
      "REAL:\tlabels . put ( label , nTarget ) ;\n",
      "IN:\tpublic void run ( ) { try {\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000001 ) == 0x00000001 ) ) {\n",
      "REAL:\twhile ( true ) {\n",
      "IN:\tpublic Object clone ( ) { try { return super . clone ( ) ; } catch ( CloneNotSupportedException e ) { throw new InternalError ( ) ; }\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprotected void writeLengthTo ( Output output , int len , boolean primitive ) throws IOException { if ( primitive ) output . writeInt32 ( ArraySchemas . ID_ARRAY_LEN , len , false ) ; else output . writeInt32 ( ArraySchemas . ID_ARRAY_LEN , - ( len + 1 ) , false ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic Avg and ( String fieldReference ) { Assert . notNull ( fieldReference , \" \" ) ;\n",
      "PRED:\treturn this ;\n",
      "REAL:\treturn new Avg ( append ( Fields . field ( fieldReference ) ) ) ;\n",
      "IN:\tprotected void paintComponent ( Graphics g ) { String snippetKey = getCurrentSnippetKey ( ) ; if ( snippetKey != NO_SNIPPET_SELECTED ) { int snippetTotal = 0 ; int snippetIndex = 0 ; List < Snippet > snippetList = null ; URL files [ ] = snippetMap . getFilesForSet ( snippetKey ) ; for ( URL file : files ) { CodeFileInfo codeFileInfo = codeCache . get ( file ) ; if ( this . codeFileInfo == codeFileInfo ) { snippetList = codeFileInfo . snippets . get ( snippetKey ) ;\n",
      "PRED:\t}\n",
      "REAL:\tsnippetIndex = snippetTotal + 1 ;\n",
      "IN:\tpublic void trace ( String format , Object arg ) { if ( logger . isLoggable ( Level . FINEST ) ) { FormattingTuple ft = MessageFormatter . format ( format , arg ) ;\n",
      "PRED:\t}\n",
      "REAL:\tlog ( SELF , Level . FINEST , ft . getMessage ( ) , ft . getThrowable ( ) ) ;\n",
      "IN:\tpublic void testEqualsOther ( ) {\n",
      "PRED:\tfinal int [ ] = new ArrayList < > ( ) ;\n",
      "REAL:\tFoo foo = MappedBeanFactory . as ( DefaultFoo . class ) ;\n",
      "IN:\tpublic StrengthOfThePack ( UUID ownerId , CardSetInfo setInfo ) { super ( ownerId , setInfo , new CardType [ ] { CardType . SORCERY }\n",
      "PRED:\t) ;\n",
      "REAL:\t, \" \" ) ;\n",
      "IN:\tpublic void visitParameterized ( ParameterizedTypeBinding binding ) { visitRaw ( binding . genericType ( ) ) ; TypeVariableBinding [ ] typeVars = binding . typeVariables ( ) ; if ( typeVars != null ) for ( TypeVariableBinding child : typeVars ) {\n",
      "PRED:\tif ( ! ( ( ( bitField0_ & 0x00000001 ) == 0 ) ) {\n",
      "REAL:\tvisitRaw ( child ) ;\n",
      "IN:\tprivate static final Map < String , BaseExponent > suffixToBinary = new HashMap < String , BaseExponent > ( ) { {\n",
      "PRED:\t@ Override public String < String > > ( ) {\n",
      "REAL:\tput ( \" \" , new BaseExponent ( 2 , 0 , Quantity . Format . BINARY_SI ) ) ;\n",
      "test bleu score:0.2\n",
      "Iteration: 2500; Percent complete: 62.5%; Average loss: 2.1536\n",
      "IN:\tpublic static void main ( String [ ] args ) throws InterruptedException , MQClientException { DefaultMQPushConsumer consumer = new DefaultMQPushConsumer ( \" \" ) ; consumer . setNamesrvAddr ( \" \" ) ; consumer . setConsumeFromWhere ( ConsumeFromWhere . CONSUME_FROM_FIRST_OFFSET ) ; consumer . setMessageModel ( MessageModel . BROADCASTING ) ; consumer . subscribe ( \" \" , \" \" ) ; consumer . registerMessageListener ( new MessageListenerConcurrently ( ) {\n",
      "PRED:\t@ Override public void run ( ) {\n",
      "REAL:\t@ Override public ConsumeConcurrentlyStatus consumeMessage ( List < MessageExt > msgs , ConsumeConcurrentlyContext context ) {\n",
      "IN:\tpublic void save ( ) throws IOException { if ( ! grammars . isEmpty ( ) ) { log . debug ( \" \" + statusFile ) ; ObjectOutputStream out = new ObjectOutputStream ( new FileOutputStream ( statusFile ) ) ; try {\n",
      "PRED:\tfinal long [ ] = new long [ 2 ] ;\n",
      "REAL:\tout . writeObject ( grammars ) ;\n",
      "IN:\tprivate void configureSnippetSetsComboBox ( ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000004 ) == 0 ) ) {\n",
      "REAL:\tTreeSet sortedSnippets = new TreeSet ( snippetMap . keySet ( ) ) ;\n",
      "IN:\tpublic static HttpRequestBody xml ( String xml , String encoding ) { try { return new HttpRequestBody ( xml . getBytes ( encoding ) , ContentType . XML , encoding ) ; }\n",
      "PRED:\tcatch ( NoClassDefFoundError e ) {\n",
      "REAL:\tcatch ( UnsupportedEncodingException e ) {\n",
      "IN:\tpublic DiscoveredSolution run ( VehicleRoutingProblem vrp , Collection < VehicleRoutingProblemSolution > solutions ) { VehicleRoutingProblemSolution solution = solutionSelector . selectSolution ( solutions ) ; if ( solution == null ) throw new IllegalStateException ( getErrMsg ( ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tVehicleRoutingProblemSolution lastSolution = VehicleRoutingProblemSolution . copyOf ( solution ) ;\n",
      "IN:\tpublic static void main ( String [ ] pArgs ) throws SQLException , IOException { String user = null ; String password = null ; String url = null ; String driver = null ; String configFileName = null ;\n",
      "PRED:\tString configFileName = \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \" \" + \"\n",
      "REAL:\tString scriptFileName = null ;\n",
      "IN:\tprivate void warmUp ( ) { ArrayList < String > list = randomStringList ( 10 ) ; for ( int i = 0 ; i < 20000 ; i ++ ) { minStringForLoop ( list ) ; minStringStream ( list ) ;\n",
      "PRED:\t}\n",
      "REAL:\tminStringParallelStream ( list ) ;\n",
      "IN:\tpublic BufferedOutputFileImpl ( OutputParams params ) { configuration = PMS . getConfiguration ( params ) ;\n",
      "PRED:\tif ( isInitialized != null ) {\n",
      "REAL:\tthis . renderer = params . mediaRenderer ;\n",
      "IN:\tpublic Builder setItems ( int index , io . kubernetes . client . proto . V1beta1Certificates . CertificateSigningRequest . Builder builderForValue ) { if ( itemsBuilder_ == null ) { ensureItemsIsMutable ( ) ; items_ . set ( index , builderForValue . build ( ) ) ; onChanged ( ) ;\n",
      "PRED:\tonChanged ( ) ;\n",
      "REAL:\t}\n",
      "IN:\tpublic static void main ( String [ ] args ) { Solution solution = new Solution ( ) ; int [ ] nums1 = new int [ 10 ] ; for ( int i = 0 ; i < 5 ; ++ i ) { nums1 [ i ] = 2 * i ; } int [ ] nums2 = new int [ 5 ] ; for ( int i = 0 ; i < 5 ; ++ i ) { nums2 [ i ] = 2 * i + 1 ; }\n",
      "PRED:\t}\n",
      "REAL:\tsolution . merge ( nums1 , 5 , nums2 , 5 ) ;\n",
      "IN:\tprivate boolean shouldFloodTo ( Hash key , int type , SigType lsSigType , Hash peer , RouterInfo target ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & Opcodes ) == 0 ) ) {\n",
      "REAL:\tif ( ( target == null ) || ( _context . banlist ( ) . isBanlisted ( peer ) ) ) return false ;\n",
      "IN:\tpublic static RuntimeTestDescriptor [ ] getAllTestDescriptors ( ) { return BaseRuntimeTest . getRuntimeTestDescriptors ( SemPredEvalLexerDescriptors . class , \" \" ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void streamListener_messageRead ( ) { ServerStreamListenerImpl < Long > streamListener = new ServerCallImpl . ServerStreamListenerImpl < > ( call , callListener , context ) ;\n",
      "PRED:\tfor ( int i = 0 ;\n",
      "REAL:\tstreamListener . messagesAvailable ( new SingleMessageProducer ( UNARY_METHOD . streamRequest ( 1234L ) ) ) ;\n",
      "IN:\tprotected void doPut ( HttpServletRequest req , HttpServletResponse res ) throws ServletException , IOException { super . doPut ( req , res ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic static ChannelBuffer getLoginBuffer ( String refKey , ChannelBuffer udpAddress ) { ChannelBuffer opcode = ChannelBuffers . buffer ( 1 ) ; ChannelBuffer protocol = ChannelBuffers . buffer ( 1 ) ; opcode . writeByte ( Events . LOG_IN ) ; protocol . writeByte ( Events . PROTCOL_VERSION ) ; String username = \" \" ; String password = \" \" ; ChannelBuffer buffer = ChannelBuffers . wrappedBuffer ( opcode , protocol , NettyUtils . writeStrings ( username , password , refKey ) , udpAddress ) ; return buffer ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprotected Encounter createEncounter ( ) { switch ( encounterKind ) {\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED:\tcase DISK : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case case : case\n",
      "REAL:\tcase DISK : return new DiskEncounter ( api , this ) ;\n",
      "IN:\tpublic List < String > tokenize ( String text ) { List < String > tokens = new ArrayList < > ( Arrays . asList ( text . split ( \" \" ) ) ) ;\n",
      "PRED:\tfor ( String e : files ) {\n",
      "REAL:\treturn tokens ;\n",
      "IN:\tprivate static float [ ] identity ( int n ) {\n",
      "PRED:\tint n = 0 ;\n",
      "REAL:\tfinal float [ ] a = new float [ n ] ;\n",
      "IN:\tpublic void testFindTextInChildProperty ( ) throws Exception { ModelDriven action = new ModelDrivenAction2 ( ) ; TestBean2 bean = ( TestBean2 ) action . getModel ( ) ; Bar bar = new Bar ( ) ; bean . setBarObj ( bar ) ; Mock mockActionInvocation = new Mock ( ActionInvocation . class ) ; mockActionInvocation . expectAndReturn ( \" \" , 0 ) ; mockActionInvocation . expectAndReturn ( \" \" , action ) ;\n",
      "PRED:\t}\n",
      "REAL:\tActionContext . getContext ( ) . setActionInvocation ( ( ActionInvocation ) mockActionInvocation . proxy ( ) ) ;\n",
      "IN:\tpublic Result resolve ( List < PluginDescriptor > plugins ) { dependenciesGraph = new DirectedGraph < > ( ) ; dependentsGraph = new DirectedGraph < > ( ) ; Map < String , PluginDescriptor > pluginByIds = new HashMap < > ( ) ; for ( PluginDescriptor plugin : plugins ) { addPlugin ( plugin ) ;\n",
      "PRED:\t}\n",
      "REAL:\tpluginByIds . put ( plugin . getPluginId ( ) , plugin ) ;\n",
      "train bleu score:0.18308781502249222\n",
      "IN:\tpublic void setActiveColor_LeavesOtherValuesIntact ( ) { bottomBar . setActiveTabColor ( Color . BLUE ) ; BottomBarTab inActiveTab = bottomBar . getTabAtPosition ( 1 ) ; assertNotEquals ( inActiveTab , bottomBar . getCurrentTab ( ) ) ; assertEquals ( INACTIVE_TAB_ALPHA , inActiveTab . getInActiveAlpha ( ) , 0 ) ; assertEquals ( ACTIVE_TAB_ALPHA , inActiveTab . getActiveAlpha ( ) , 0 ) ; assertEquals ( INACTIVE_TAB_COLOR , inActiveTab . getInActiveColor ( ) ) ; assertEquals ( Color . BLUE , inActiveTab . getActiveColor ( ) ) ;\n",
      "PRED:\tassertEquals ( \" \" , toSummaryString . get ( 0 ) ) ;\n",
      "REAL:\tassertEquals ( BACKGROUND_COLOR , inActiveTab . getBarColorWhenSelected ( ) ) ;\n",
      "IN:\tprivate void rotateByAngle ( int angle ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & Opcodes ) == 0 ) ) {\n",
      "REAL:\tmGestureCropImageView . postRotate ( angle ) ;\n",
      "IN:\tprivate static boolean isInterface ( Class < ? > cls , Class < ? > intfc ) { try { Class < ? > [ ] intfcs = cls . getInterfaces ( ) ; for ( int i = 0 ; i < intfcs . length ; i ++ ) { if ( intfcs [ i ] == intfc ) return true ; } }\n",
      "PRED:\t}\n",
      "REAL:\tcatch ( Throwable t ) {\n",
      "IN:\tpublic Long size ( ) { synchronized ( mLock ) { Long size = 0L ; if ( exists ( ) ) { if ( isDirectory ( ) ) { String [ ] list = getList ( ) ; if ( list != null ) {\n",
      "PRED:\treturn new File ( new String ( ) ) ;\n",
      "REAL:\tString path = getAbsolutePath ( ) ;\n",
      "IN:\tprotected void addAttributeProcessors ( ) { addAttributeProcessor ( Attributes . ScrollView . Scrollbars , new StringAttributeProcessor < T > ( ) { @ Override public void setString ( T view , String value ) { if ( \" \" . equals ( value ) ) { view . setHorizontalScrollBarEnabled ( false ) ; view . setVerticalScrollBarEnabled ( false ) ; }\n",
      "PRED:\t}\n",
      "REAL:\telse if ( \" \" . equals ( value ) ) {\n",
      "IN:\tprotected < T > Schema < T > newSchema ( Class < T > typeClass ) { if ( primaryGroup == null ) return RuntimeSchema . createFrom ( typeClass , this ) ;\n",
      "PRED:\t}\n",
      "REAL:\tfinal Schema < T > s = primaryGroup . getSchemaWrapper ( typeClass , true ) . getSchema ( ) ;\n",
      "IN:\tpublic void actionPerformed ( ActionEvent actionEvent ) { T selectedTreeNode = ( T ) searchInConstantPoolsTree . getLastSelectedPathComponent ( ) ; if ( selectedTreeNode != null ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000001 ) == 0 ) ) {\n",
      "REAL:\tselectedTypeCallback . accept ( selectedTreeNode . getUri ( ) , searchInConstantPoolsEnterTextField . getText ( ) , getFlags ( ) ) ;\n",
      "IN:\tprivate boolean verifyHostName ( String hostName , X509Certificate certificate ) { hostName = hostName . toLowerCase ( Locale . US ) ; boolean hasDns = false ; List < String > altNames = getSubjectAltNames ( certificate , ALT_DNS_NAME ) ; for ( int i = 0 , size = altNames . size ( ) ; i < size ; i ++ ) { hasDns = true ; if ( verifyHostName ( hostName , altNames . get ( i ) ) ) { return true ; } } if ( ! hasDns ) {\n",
      "PRED:\treturn false ;\n",
      "REAL:\tX500Principal principal = certificate . getSubjectX500Principal ( ) ;\n",
      "IN:\tpublic void onTabReSelected ( @ IdRes int tabId ) { Toast . makeText ( getApplicationContext ( ) , TabMessage . get ( tabId , true ) , Toast . LENGTH_LONG ) . show ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic final void initialize ( final HttpRequest request ) { request . setReadTimeout ( 2 * ONE_MINUTE_MILLIS ) ; final HttpUnsuccessfulResponseHandler backoffHandler = new HttpBackOffUnsuccessfulResponseHandler ( new ExponentialBackOff ( ) ) . setSleeper ( sleeper ) ; request . setInterceptor ( wrappedCredential ) ; request . setUnsuccessfulResponseHandler ( new HttpUnsuccessfulResponseHandler ( ) {\n",
      "PRED:\t@ Override public void run ( ) {\n",
      "REAL:\t@ Override public boolean handleResponse ( final HttpRequest request , final HttpResponse response , final boolean supportsRetry ) throws IOException {\n",
      "IN:\tprivate static final Object [ ] [ ] OBJECTS = new Object [ ] [ ] { { \" \" , \" \" } , { \" \" , \" \" } , {\n",
      "PRED:\t\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \"\n",
      "REAL:\t\" \" , \" \" }\n",
      "IN:\tpublic AnnotationVisitor visitLocalVariableAnnotation ( int typeRef , TypePath typePath , Label [ ] start , Label [ ] end , int [ ] index , String desc , boolean visible ) {\n",
      "PRED:\tif ( points == null ) {\n",
      "REAL:\tAnnotationVisitor av = super . visitLocalVariableAnnotation ( typeRef , typePath , start , end , index , remapper . mapDesc ( desc ) , visible ) ;\n",
      "IN:\tpublic Builder setJobTemplate ( io . kubernetes . client . proto . V1beta1Batch . JobTemplateSpec value ) { if ( jobTemplateBuilder_ == null ) { if ( value == null ) { throw new NullPointerException ( ) ; } jobTemplate_ = value ; onChanged ( ) ; } else { jobTemplateBuilder_ . setMessage ( value ) ; } bitField0_ |= 0x00000010 ; return this ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic static NodeVo fromDefaultNode ( DefaultNode node , String parentId ) { if ( node == null ) { return null ; } NodeVo vo = new NodeVo ( ) ; vo . id = UUID . randomUUID ( ) . toString ( ) ; vo . parentId = parentId ; vo . resource = node . getId ( ) . getShowName ( ) ; vo . threadNum = node . curThreadNum ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tvo . passQps = ( long ) node . passQps ( ) ;\n",
      "IN:\tprivate float resize ( ) { final BitmapFactory . Options options = new BitmapFactory . Options ( ) ; options . inJustDecodeBounds = true ;\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000004 ) == 0 ) ) {\n",
      "REAL:\tBitmapFactory . decodeFile ( mImageInputPath , options ) ;\n",
      "IN:\tpublic static io . kubernetes . client . proto . V1beta1Authentication . UserInfo parseFrom ( java . nio . ByteBuffer data , com . google . protobuf . ExtensionRegistryLite extensionRegistry ) throws com . google . protobuf . InvalidProtocolBufferException { return PARSER . parseFrom ( data , extensionRegistry ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic AnnotationSpec build ( ) { for ( String name : members . keySet ( ) ) { checkNotNull ( name , \" \" ) ; checkArgument ( SourceVersion . isName ( name ) , \" \" , name ) ; } return new AnnotationSpec ( this ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic MethodProxy ( Method pMethod , Object pDelegate ) { if ( pMethod == null ) { throw new IllegalArgumentException ( \" \" ) ; } if ( pDelegate == null ) { throw new IllegalArgumentException ( \" \" ) ; }\n",
      "PRED:\t}\n",
      "REAL:\tmMethod = pMethod ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN:\tprivate void calculateRay ( Vector direction , Collection < BlockVector > result ) { Location current = location . clone ( ) ; float currentPower = calculateStartPower ( ) ; while ( currentPower > 0 ) { GlowBlock block = world . getBlockAt ( current ) ; if ( block . getType ( ) != Material . AIR ) { double blastDurability = getBlastDurability ( block ) / 5d ; blastDurability += 0.3F ; blastDurability *= 0.3F ; currentPower -= blastDurability ;\n",
      "PRED:\t}\n",
      "REAL:\tif ( currentPower > 0 ) {\n",
      "IN:\tpublic @ interface Delegate { Class < ? > [ ] types ( ) default { } ; Class < ? > [ ] excludes ( ) default {\n",
      "PRED:\treturn new String [ ] {\n",
      "REAL:\t}\n",
      "test bleu score:0.2173497411656474\n",
      "Iteration: 3000; Percent complete: 75.0%; Average loss: 1.9761\n",
      "IN:\tpublic RestCfg ( String resource ) throws IOException { this ( RestCfg . class . getClassLoader ( ) . getResourceAsStream ( resource ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void propertyChange ( PropertyChangeEvent evt ) { String prop = ( String ) evt . getPropertyName ( ) ; if ( prop . equals ( JInternalFrame . IS_SELECTED_PROPERTY ) ) { Boolean b = ( Boolean ) evt . getNewValue ( ) ; iconButton . putClientProperty ( \" \" , b ) ; closeButton . putClientProperty ( \" \" , b ) ; maxButton . putClientProperty ( \" \" , b ) ; }\n",
      "PRED:\t}\n",
      "REAL:\telse if ( \" \" . equals ( prop ) ) {\n",
      "IN:\tpublic void testIterator ( ) { Attributes a = new Attributes ( ) ; String [ ] [ ] datas = { { \" \" , \" \" } , { \" \" , \" \" }\n",
      "PRED:\t) ;\n",
      "REAL:\t, {\n",
      "IN:\tprivate void addTestsFromTestCase ( final Class < ? > theClass ) { fName = theClass . getName ( ) ; try { getTestConstructor ( theClass ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic Array ( Value [ ] values ) { this . values = Arrays . asList ( values ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic int hashCode ( ) { if ( memoizedHashCode != 0 ) { return memoizedHashCode ; }\n",
      "PRED:\telse {\n",
      "REAL:\tint hash = 41 ;\n",
      "IN:\tpublic final void run ( ) { beforeRun ( ) ; try { runnable . run ( ) ; } finally { afterRun ( ) ; }\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic static void registerAction ( @ NotNull Project project , @ NotNull String id , @ NotNull AnAction action ) {\n",
      "PRED:\tif ( ! ( ( MapWrapper & Opcodes . ACC_SYNTHETIC ) == 0 ) ) {\n",
      "REAL:\tMap < String , AnAction > actions = project . getUserData ( PROJECT_ACTIONS_KEY ) ;\n",
      "IN:\tprivate void validateLocalizedString ( Set < String > bundleKeys , Set < String > missingRegisteredKeys , Set < String > unusedKeys , LocalizedStringImpl localized ) { String key = localized . getKey ( ) ; if ( bundleKeys . contains ( key ) ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & & 0x00000001 ) & 0x00000001 ) ) {\n",
      "REAL:\tunusedKeys . remove ( key ) ;\n",
      "IN:\tprivate void jsonError ( final JsonParseException ex , final HttpServletRequest request , final HttpServletResponse response ) throws IOException { Map < String , Object > root = new HashMap < String , Object > ( ) ; Map < String , Object > error = new HashMap < String , Object > ( ) ;\n",
      "PRED:\tif ( ! ( ( key ) directory ) . equals ( preferences . get ( \" \" ) ) ) {\n",
      "REAL:\tString filename = jsonFilename ( request ) ;\n",
      "IN:\tpublic void testOrElseGet ( ) { assertThat ( none . orElseGet ( ( ) -> 2 ) , equalTo ( 2 ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tassertThat ( just . orElseGet ( ( ) -> 2 ) , equalTo ( 10 ) ) ;\n",
      "IN:\tpublic boolean equals ( Object obj ) { if ( obj instanceof StatusCode ) { return this . value == ( ( StatusCode ) obj ) . value ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic StormscaleAnarch ( UUID ownerId , CardSetInfo setInfo ) { super ( ownerId , setInfo , new CardType [ ] { CardType . CREATURE } , \" \" ) ; this . subtype . add ( SubType . VIASHINO ) ; this . subtype . add ( SubType . SHAMAN ) ; this . power = new MageInt ( 2 ) ;\n",
      "PRED:\tthis . toughness = new MageInt ( new byte [ ] {\n",
      "REAL:\tthis . toughness = new MageInt ( 2 ) ;\n",
      "IN:\tprotected Set < ApplicationResource > findResources ( String path ) throws IOException { Set < ApplicationResource > resources = new HashSet < > ( ) ; LOG . trace ( \" \" , path ) ; Pattern pattern = WildcardUtil . compileWildcardPattern ( path ) ; Map < String , URL > matches = finder . getResourcesMap ( \" \" ) ;\n",
      "PRED:\tif ( ! ( ( bitField0_ & & 0x00000001 ) == 0 ) ) {\n",
      "REAL:\tfor ( Map . Entry < String , URL > entry : matches . entrySet ( ) ) {\n",
      "IN:\tpublic void testMatchAnyPart ( ) { final String [ ] partsA = new String [ ] { \" \" } ; final String [ ] partsB = new String [ ] { \" \" , \" \" } ; assertFalse ( MatcherUtil . matchAnyPart ( null , null ) ) ; assertFalse ( MatcherUtil . matchAnyPart ( null , \" \" ) ) ; assertFalse ( MatcherUtil . matchAnyPart ( partsA , null ) ) ; assertFalse ( MatcherUtil . matchAnyPart ( partsA , \" \" ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tassertTrue ( MatcherUtil . matchAnyPart ( partsA , \" \" ) ) ;\n",
      "IN:\tprivate TokenReviewSpec ( com . google . protobuf . CodedInputStream input , com . google . protobuf . ExtensionRegistryLite extensionRegistry ) throws com . google . protobuf . InvalidProtocolBufferException { this ( ) ; if ( extensionRegistry == null ) { throw new java . lang . NullPointerException ( ) ; } int mutable_bitField0_ = 0 ;\n",
      "PRED:\treturn ;\n",
      "REAL:\tcom . google . protobuf . UnknownFieldSet . Builder unknownFields = com . google . protobuf . UnknownFieldSet . newBuilder ( ) ;\n",
      "IN:\tprivate static boolean isEscapeNeededForString ( String str , int len ) { boolean needsHexEscape = false ; for ( int i = 0 ; i < len ; ++ i ) { char c = str . charAt ( i ) ; switch ( c ) { case 0 : needsHexEscape = true ; break ; case \" \" : needsHexEscape = true ; break ;\n",
      "PRED:\tbreak ;\n",
      "REAL:\tcase \" \" : needsHexEscape = true ;\n",
      "IN:\tpublic void setStream_isReady ( ) { stream . start ( listener ) ;\n",
      "PRED:\t}\n",
      "REAL:\tassertFalse ( stream . isReady ( ) ) ;\n",
      "IN:\tpublic CLI addArgument ( Argument arg ) { Objects . requireNonNull ( arg ) ; arguments . add ( arg ) ; return this ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprivate static File getPreferencesFile ( ) {\n",
      "PRED:\treturn new String [ ] {\n",
      "REAL:\tString home = System . getProperty ( \" \" ) ;\n",
      "train bleu score:0.3231618079884146\n",
      "IN:\tpublic void counter ( Vertx vertx ) {\n",
      "PRED:\tif ( ! resolved . succeeded ( ) ) {\n",
      "REAL:\tSharedData sharedData = vertx . sharedData ( ) ;\n",
      "IN:\tpublic MethodProxy ( Method pMethod , Object pDelegate ) {\n",
      "PRED:\tsuper ( new ValidationError ( ) ) ;\n",
      "REAL:\tif ( pMethod == null ) {\n",
      "IN:\tpublic void destroy ( ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000001 ) == 0x00000001 ) ) {\n",
      "REAL:\ttry {\n",
      "IN:\tpublic VariableStatsEstimate getVariableStatistics ( VariableReferenceExpression variable ) { return variableStatistics . getOrDefault ( variable , VariableStatsEstimate . unknown ( ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprivate static ECPrivateKey cvtToJavaECKey ( SigningPrivateKey pk ) throws GeneralSecurityException { SigType type = pk . getType ( ) ;\n",
      "PRED:\tif ( ! ( ( bitField0_ & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & 0xFF ) ) ) {\n",
      "REAL:\tbyte [ ] b = pk . getData ( ) ;\n",
      "IN:\tpublic void testPreProcess ( ) throws Exception { StemmingPreprocessor preprocessor = new StemmingPreprocessor ( ) ; String test = \" \" ; String output = preprocessor . preProcess ( test ) ; System . out . println ( \" \" + output ) ; assertEquals ( \" \" , output ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic ZStat ( String path , String uri , byte [ ] data64 , String dataUtf8 , long czxid , long mzxid , long ctime , long mtime , int version , int cversion , int aversion , long ephemeralOwner , int dataLength , int numChildren , long pzxid ) { this . path = path ; this . uri = uri ; this . data64 = data64 ; this . dataUtf8 = dataUtf8 ; this . czxid = czxid ; this . mzxid = mzxid ;\n",
      "PRED:\tthis . grammars = new MageInt ( new byte [ ] {\n",
      "REAL:\tthis . ctime = ctime ;\n",
      "IN:\tpublic Builder clearField ( com . google . protobuf . Descriptors . FieldDescriptor field ) {\n",
      "PRED:\tif ( other . equals ( other . kubernetes . client . proto . Meta . Status ) ) {\n",
      "REAL:\treturn ( Builder ) super . clearField ( field ) ;\n",
      "IN:\tpublic boolean createPath ( String path , String data ) {\n",
      "PRED:\tif ( ! ( expression instanceof MessageSelector ) ) {\n",
      "REAL:\ttry {\n",
      "IN:\tpublic boolean equals ( Object o ) { if ( o == this ) { return true ; } if ( ! ( o instanceof Value ) ) { return false ; } Value v = ( Value ) o ; if ( ! v . isIntegerValue ( ) ) { return false ; } IntegerValue iv = v . asIntegerValue ( ) ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000001 ) == 0 ) ) {\n",
      "REAL:\treturn value . equals ( iv . toBigInteger ( ) ) ;\n",
      "IN:\tprivate void calculateRay ( Vector direction , Collection < BlockVector > result ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000001 ) == 0x00000001 ) ) {\n",
      "REAL:\tLocation current = location . clone ( ) ;\n",
      "IN:\tpublic void distinctAsync_noneExistingField ( ) throws Throwable { Realm realm = looperThread . getRealm ( ) ; final long numberOfBlocks = 25 ; final long numberOfObjects = 10 ; populateForDistinct ( realm , numberOfBlocks , numberOfObjects , false ) ; try { realm . where ( AnnotationIndexTypes . class ) . distinct ( \" \" ) . findAllAsync ( ) ; fail ( ) ; } catch ( IllegalArgumentException ignored ) {\n",
      "PRED:\t}\n",
      "REAL:\tlooperThread . testComplete ( ) ;\n",
      "IN:\tpublic boolean accept ( API api , Path rootPath ) { if ( rootPath . toUri ( ) . toString ( ) . toLowerCase ( ) . endsWith ( \" \" ) ) {\n",
      "PRED:\treturn true ;\n",
      "REAL:\treturn true ;\n",
      "IN:\tprivate void handlebarsError ( final HandlebarsException ex , final HttpServletResponse response ) throws IOException { HandlebarsError error = ex . getError ( ) ; int firstLine = 1 ; if ( error != null ) { if ( ex . getCause ( ) != null ) { firstLine = error . line ; } else { firstLine = Math . max ( 1 , error . line - 1 ) ; } }\n",
      "PRED:\telse {\n",
      "REAL:\tfancyError ( ex , firstLine , \" \" , response ) ;\n",
      "IN:\tprotected ClassLoader overrideThreadContextClassLoader ( ClassLoader loader ) { Thread currentThread = Thread . currentThread ( ) ; ClassLoader threadContextClassLoader = currentThread . getContextClassLoader ( ) ; if ( loader != null && ! loader . equals ( threadContextClassLoader ) ) { currentThread . setContextClassLoader ( loader ) ; return threadContextClassLoader ; }\n",
      "PRED:\t}\n",
      "REAL:\telse {\n",
      "IN:\tpublic Builder setTemplate ( io . kubernetes . client . proto . V1 . PodTemplateSpec value ) { if ( templateBuilder_ == null ) { if ( value == null ) { throw new NullPointerException ( ) ; } template_ = value ; onChanged ( ) ; } else { templateBuilder_ . setMessage ( value ) ; }\n",
      "PRED:\tbitField0_ |= 0x00000002 ;\n",
      "REAL:\tbitField0_ |= 0x00000040 ;\n",
      "IN:\tpublic MyCompletableFuture < User > createUser2 ( ) { MyCompletableFuture < User > f = new MyCompletableFuture < > ( ) ; new Thread ( ( ) -> { try {\n",
      "PRED:\treturn new PrimitiveConverter < ? > > ( ) {\n",
      "REAL:\tThread . sleep ( 1000 ) ;\n",
      "IN:\tpublic SelenideElement execute ( SelenideElement proxy , WebElementSource locator , Object [ ] args ) { SelenideElement target ; if ( args [ 0 ] instanceof String ) {\n",
      "PRED:\treturn new String [ ] {\n",
      "REAL:\ttarget = ElementFinder . wrap ( locator . driver ( ) , By . cssSelector ( ( String ) args [ 0 ] ) ) ;\n",
      "IN:\tprivate java . lang . reflect . Type localVariable ( final MethodNode m , final VarInsnNode varInsn ) { if ( varInsn . getOpcode ( ) == Opcodes . ALOAD ) { List < LocalVariableNode > vars = m . localVariables ; LocalVariableNode var = vars . stream ( ) . filter ( v -> v . index == varInsn . var ) . findFirst ( ) . orElse ( null ) ; if ( var != null ) {\n",
      "PRED:\treturn new ArrayList < ? > > ( ) {\n",
      "REAL:\tString signature = Optional . ofNullable ( var . signature ) . orElse ( var . desc ) ;\n",
      "IN:\tpublic void testClone ( ) { IntArraySet s = new IntArraySet ( ) ; assertEquals ( s , s . clone ( ) ) ; s . add ( 0 ) ; assertEquals ( s , s . clone ( ) ) ; s . add ( 0 ) ; assertEquals ( s , s . clone ( ) ) ; s . add ( 1 ) ; assertEquals ( s , s . clone ( ) ) ; s . add ( 2 ) ; assertEquals ( s , s . clone ( ) ) ;\n",
      "PRED:\tassertEquals ( 1 , s . get ( 0 ) ) ;\n",
      "REAL:\ts . remove ( 0 ) ;\n",
      "test bleu score:0.15\n",
      "Iteration: 3500; Percent complete: 87.5%; Average loss: 1.8340\n",
      "IN:\tpublic Boolean setSwapOn ( Integer priority ) { if ( exists ( ) ) { Boolean status = isActive ( ) ; if ( ! status ) { String [ ] commands = null ; if ( priority > 0 ) { commands = new String [ ] {\n",
      "PRED:\t\" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \" \" , \"\n",
      "REAL:\t\" \" + priority + \" \" + mSwapDevice . getAbsolutePath ( ) + \" \" , \" \" + mSwapDevice . getAbsolutePath ( ) + \" \" }\n",
      "IN:\tpublic I category ( String category ) {\n",
      "PRED:\tif ( this . name == null ) {\n",
      "REAL:\tintent . addCategory ( category ) ;\n",
      "IN:\tpublic static boolean isPrime ( BigInteger n ) { var counter = BigInteger . ONE . add ( BigInteger . ONE ) ; var isPrime = true ; while ( counter . compareTo ( n ) == - 1 ) { if ( n . remainder ( counter ) . compareTo ( BigInteger . ZERO ) == 0 ) { isPrime = false ; break ; } counter = counter . add ( BigInteger . ONE ) ; } return isPrime ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprotected void initDelegate ( Configuration config ) {\n",
      "PRED:\tif ( ! ( ( bitField0_ & 0x00000001 ) == 0x00000001 ) ) {\n",
      "REAL:\tString location = NetworkUtil . replaceExpression ( config . get ( ConfigKey . POLICY_LOCATION ) ) ;\n",
      "IN:\tpublic void testRadixSort2 ( ) {\n",
      "PRED:\tint i = 0 ;\n",
      "REAL:\tint [ ] [ ] d = new int [ 2 ] [ ] ;\n",
      "IN:\tpublic static boolean isEmpty ( Iterator < ? > Iterator ) { return null == Iterator || false == Iterator . hasNext ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void goForward ( ) { if ( null != mWebView ) { mWebView . goForward ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void testFindClassNames ( ) { ExtensionFinder instance = new AbstractExtensionFinder ( pluginManager ) { @ Override public Map < String , Set < String > > readPluginsStorages ( ) { Map < String , Set < String > > entries = new LinkedHashMap < > ( ) ; Set < String > bucket = new HashSet < > ( ) ;\n",
      "PRED:\tfor ( String s : list ) {\n",
      "REAL:\tbucket . add ( \" \" ) ;\n",
      "IN:\tpublic void setItemsWithCustomConfig_OverridesPreviousValues ( ) { BottomBar newBar = new BottomBar ( context ) ; newBar . setItems ( THREE_TABS , DEFAULT_CONFIG ) ; BottomBarTab first = newBar . getTabAtPosition ( 0 ) ; assertEquals ( INACTIVE_TAB_ALPHA , first . getInActiveAlpha ( ) , 0 ) ; assertEquals ( ACTIVE_TAB_ALPHA , first . getActiveAlpha ( ) , 0 ) ; assertEquals ( INACTIVE_TAB_COLOR , first . getInActiveColor ( ) ) ; assertEquals ( ACTIVE_TAB_COLOR , first . getActiveColor ( ) ) ; assertEquals ( BACKGROUND_COLOR , first . getBarColorWhenSelected ( ) ) ;\n",
      "PRED:\tassertEquals ( \" \" , toSummaryString ( ) . get ( 0 ) ) ;\n",
      "REAL:\tassertEquals ( BADGE_BACKGROUND_COLOR , first . getBadgeBackgroundColor ( ) ) ;\n",
      "IN:\tpublic SenderKeyDistributionMessage ( byte [ ] serialized ) throws LegacyMessageException , InvalidMessageException { try { byte [ ] [ ] messageParts = ByteUtil . split ( serialized , 1 , serialized . length - 1 ) ; byte version = messageParts [ 0 ] [ 0 ] ; byte [ ] message = messageParts [ 1 ] ; if ( ByteUtil . highBitsToInt ( version ) < CiphertextMessage . CURRENT_VERSION ) { throw new LegacyMessageException ( \" \" + ByteUtil . highBitsToInt ( version ) ) ; }\n",
      "PRED:\telse {\n",
      "REAL:\tif ( ByteUtil . highBitsToInt ( version ) > CURRENT_VERSION ) {\n",
      "IN:\tpublic void keyPressed ( KeyEvent e ) {\n",
      "PRED:\te . printStackTrace ( ) ;\n",
      "REAL:\tdebug ( \" \" + e + \" \" ) ;\n",
      "IN:\tprivate void invokeChainedMethod ( WebSocketSession session , Event event ) { Queue < MethodWrapper > queue = conversationQueueMap . get ( event . getChannelId ( ) ) ; if ( queue != null && ! queue . isEmpty ( ) ) { MethodWrapper methodWrapper = queue . peek ( ) ; try { EventType [ ] eventTypes = methodWrapper . getMethod ( ) . getAnnotation ( Controller . class ) . events ( ) ; for ( EventType eventType : eventTypes ) {\n",
      "PRED:\tif ( ! ( ( ConversationAdapter ) directory ) . containsTag ( GifHeaderDirectory . TAG_IMAGE_HEIGHT ) ) {\n",
      "REAL:\tif ( eventType . name ( ) . equalsIgnoreCase ( event . getType ( ) ) ) {\n",
      "IN:\tprivate void refreshReport ( ) { try { mActivityRule . runOnUiThread ( new Runnable ( ) { @ Override public void run ( ) { mReportsActivity . refresh ( ) ; }\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void close ( ) { isShuttingDown = true ; eventDispatcher . close ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tif ( null != tcpMessageSender ) {\n",
      "IN:\tpublic void testRadixSort2 ( ) { double [ ] [ ] d = new double [ 2 ] [ ] ; d [ 0 ] = new double [ 10 ] ;\n",
      "PRED:\tfor ( int i = 0 ;\n",
      "REAL:\tfor ( int i = d [ 0 ] . length ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN:\tpublic void setNumbers ( Map < Integer , ? extends COSObjectable > numbers ) { if ( numbers == null ) { node . setItem ( COSName . NUMS , ( COSObjectable ) null ) ; node . setItem ( COSName . LIMITS , ( COSObjectable ) null ) ; }\n",
      "PRED:\telse {\n",
      "REAL:\telse {\n",
      "IN:\tpublic String [ ] getSupportedExtensions ( ) { return new String [ ] { \" \" , \" \" , \" \" } ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprivate static final String getLibrarySuffix ( ) {\n",
      "PRED:\tString [ ] bytes = new String [ ] {\n",
      "REAL:\tif ( isWindows ) return \" \" ;\n",
      "IN:\tpublic static int crossShape ( Shape s , double x , double y ) { if ( ! s . getBounds2D ( ) . contains ( x , y ) ) { return 0 ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void run ( ) { try { task . run ( ) ; } catch ( Throwable t ) { log . log ( Level . SEVERE , \" \" + task , t ) ;\n",
      "PRED:\t}\n",
      "REAL:\tThrowables . throwIfUnchecked ( t ) ;\n",
      "train bleu score:0.39090257804247436\n",
      "IN:\tpublic void run ( ) { appWindow . setContentPane ( appWindowContent ) ; appWindow . pack ( ) ; StringBuilder installSpecific = new StringBuilder ( ) ; for ( String installSpecificMessage : installSpecificMessages ) { installSpecific . append ( \" \" ) . append ( installSpecificMessage ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void testBatchingCollectorMaxActive ( ) { collector = new BatchingCollector ( new MaxActive ( 10 , 5 ) , LazyReact . sequentialBuilder ( ) . of ( 1 ) ) . withResults ( new HashSet < > ( ) ) ; FastFuture cf = Mockito . mock ( FastFuture . class ) ;\n",
      "PRED:\tfor ( int i = 0 ;\n",
      "REAL:\tBDDMockito . given ( cf . isDone ( ) ) . willReturn ( true ) ;\n",
      "IN:\tpublic int hashCode ( ) {\n",
      "PRED:\tint hash = 41 ;\n",
      "REAL:\tif ( hash == 0 ) {\n",
      "IN:\tprotected void onPostCreate ( Bundle savedInstanceState ) {\n",
      "PRED:\tsuper . onCreate ( ) ;\n",
      "REAL:\tsuper . onPostCreate ( savedInstanceState ) ;\n",
      "IN:\tprotected String getAttribute ( @ NonNull String tableName , @ NonNull String recordUID , @ NonNull String columnName ) { Cursor cursor = mDb . query ( tableName , new String [ ] { columnName } , AccountEntry . COLUMN_UID + \" \" , new String [ ] { recordUID } , null , null , null ) ;\n",
      "PRED:\t}\n",
      "REAL:\ttry {\n",
      "IN:\tpublic T get ( InternalContext context , Dependency < ? > dependency , boolean linked ) throws InternalProvisionException { ConstructorInjector < T > localInjector = constructorInjector ; if ( localInjector == null ) { throw new IllegalStateException ( \" \" ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void testIfFindsAllPatterns ( ) { myFixture . enableInspections ( new InArrayMissUseInspector ( ) ) ;\n",
      "PRED:\tmyFixture . configureByFile ( \" \" ) ;\n",
      "REAL:\tmyFixture . configureByFile ( \" \" ) ;\n",
      "IN:\tpublic io . kubernetes . client . proto . V1beta1Batch . CronJob . Builder addItemsBuilder ( int index ) {\n",
      "PRED:\treturn io . kubernetes . client . proto . Runtime . RawExtension ;\n",
      "REAL:\treturn getItemsFieldBuilder ( ) . addBuilder ( index , io . kubernetes . client . proto . V1beta1Batch . CronJob . getDefaultInstance ( ) ) ;\n",
      "IN:\tpublic static String inboundFilter ( String s , StringBuffer expectedPong , DCCHelper helper ) { String field [ ] = DataHelper . split ( s , \" \" , 4 ) ; String command ; int idx = 0 ; try {\n",
      "PRED:\tif ( str . length ( ) < 1 ) {\n",
      "REAL:\tif ( field [ 0 ] . charAt ( 0 ) == \" \" ) idx ++ ;\n",
      "IN:\tpublic void run ( ) { Entry e = null ; try { e = SphU . entry ( \" \" ) ; synchronized ( sequence ) { System . out . println ( \" \" ) ; sequence . notify ( ) ; } Thread . sleep ( 100 ) ; }\n",
      "PRED:\tcatch ( IOException e ) {\n",
      "REAL:\tcatch ( BlockException e1 ) {\n",
      "IN:\tpublic void cancel ( ) { if ( future != null && ! future . isCancelled ( ) ) { if ( trailing ) { trailingTask = true ; }\n",
      "PRED:\t}\n",
      "REAL:\telse {\n",
      "IN:\tpublic boolean equals ( Object obj ) { if ( obj == null ) {\n",
      "PRED:\treturn true ;\n",
      "REAL:\treturn false ;\n",
      "IN:\tpublic void testNextAtEndFast ( ) { m . addTo ( 1 , 1 ) ; m . addTo ( 2 , 2 ) ; m . addTo ( 3 , 3 ) ;\n",
      "PRED:\tassertFalse ( m . remove ( 0 ) ) ;\n",
      "REAL:\tfinal ObjectBidirectionalIterator < Entry > iterator = m . int2IntEntrySet ( ) . iterator ( m . int2IntEntrySet ( ) . last ( ) ) ;\n",
      "IN:\tpublic Builder setTemplate ( io . kubernetes . client . proto . V1 . PodTemplateSpec value ) { if ( templateBuilder_ == null ) { if ( value == null ) { throw new NullPointerException ( ) ; } template_ = value ; onChanged ( ) ; } else { templateBuilder_ . setMessage ( value ) ; } bitField0_ |= 0x00000040 ; return this ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic static void writeToFile ( BitMatrix matrix , String format , File file , MatrixToImageConfig config ) throws IOException { BufferedImage image = toBufferedImage ( matrix , config ) ; if ( ! ImageIO . write ( image , format , file ) ) { throw new IOException ( \" \" + format + \" \" + file ) ; }\n",
      "PRED:\telse {\n",
      "REAL:\t}\n",
      "IN:\tpublic void delete ( Long id ) { User user = getUser ( id ) ; if ( user != null ) { userList . remove ( user ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic ClassWriter ( final ClassReader classReader , final int flags ) { super ( Opcodes . ASM7 ) ; symbolTable = classReader == null ? new SymbolTable ( this ) : new SymbolTable ( this , classReader ) ; if ( ( flags & COMPUTE_FRAMES ) != 0 ) {\n",
      "PRED:\tthis . sessionStructure = new Point2D . Element ( ) ;\n",
      "REAL:\tthis . compute = MethodWriter . COMPUTE_ALL_FRAMES ;\n",
      "IN:\tpublic Palette ( int totalRange , int minColor , int maxColor , double rStart , double gStart , double bStart , int rSteps , int gSteps , int bSteps ) { this . minColor = minColor ; this . colorRange = maxColor - minColor ; this . rStart = rStart ; this . gStart = gStart ; this . bStart = bStart ; this . rSteps = rSteps ;\n",
      "PRED:\tthis . realLineNumber = this ;\n",
      "REAL:\tthis . gSteps = gSteps ;\n",
      "IN:\tpublic void essential_notCompleted ( ) { called = false ;\n",
      "PRED:\tfinal int numOwnersOfCat1 = 0 ;\n",
      "REAL:\tFastFuture f = future . < Integer , Integer > thenApply ( i -> i + 2 ) . build ( ) ;\n",
      "test bleu score:0.3073647101379323\n",
      "Iteration: 4000; Percent complete: 100.0%; Average loss: 1.7131\n",
      "IN:\tpublic static Equality fromByte ( byte equality ) {\n",
      "PRED:\treturn new MapSqlParameterSource ( ) ;\n",
      "REAL:\tif ( equality > 0 ) {\n",
      "IN:\tpublic void testIfFindsAllPatterns ( ) {\n",
      "PRED:\tmyFixture . enableInspections ( new SimpleXmlLoadFileUsageInspector ( ) ) ;\n",
      "REAL:\tmyFixture . enableInspections ( new ClassConstantUsageCorrectnessInspector ( ) ) ;\n",
      "IN:\tpublic MQTTFrame encode ( ) { try { DataByteArrayOutputStream os = new DataByteArrayOutputStream ( ) ; QoS qos = qos ( ) ; if ( qos != QoS . AT_MOST_ONCE ) { os . writeShort ( messageId ) ; } for ( UTF8Buffer topic : topics ) { MessageSupport . writeUTF ( os , topic ) ; } MQTTFrame frame = new MQTTFrame ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tframe . header ( header ( ) ) ;\n",
      "IN:\tprivate int getScale ( ) { int scale = mCommodity . getSmallestFractionDigits ( ) ; if ( scale < 0 ) {\n",
      "PRED:\tint index = 0 ;\n",
      "REAL:\tscale = mAmount . scale ( ) ;\n",
      "IN:\tpublic static io . kubernetes . client . proto . V1alpha1Imagepolicy . ImageReviewContainerSpec parseFrom ( com . google . protobuf . ByteString data ) throws com . google . protobuf . InvalidProtocolBufferException { return PARSER . parseFrom ( data ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tprivate void annotatedEquivalence ( TypeName type ) { assertFalse ( type . isAnnotated ( ) ) ; assertEquals ( type , type ) ; assertEquals ( type . annotated ( TYPE_USE_ANNOTATION ) , type . annotated ( TYPE_USE_ANNOTATION ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tassertNotEquals ( type , type . annotated ( TYPE_USE_ANNOTATION ) ) ;\n",
      "IN:\tprotected TokenStreamComponents createComponents ( String fieldName ) { Tokenizer _IKTokenizer = new IKTokenizer ( configuration ) ;\n",
      "PRED:\tif ( ! ( ( Event ) != null ) {\n",
      "REAL:\treturn new TokenStreamComponents ( _IKTokenizer ) ;\n",
      "IN:\tprotected ContainerRequestFilter getAuthFilter ( ) {\n",
      "PRED:\treturn new Builder ( ) . mergeFrom ( new ArrayList < > ( ) {\n",
      "REAL:\tBasicCredentialAuthFilter . Builder < Principal > builder = new BasicCredentialAuthFilter . Builder < > ( ) ;\n",
      "IN:\tprivate void fixPositions ( AbstractMethodDeclaration node ) { node . sourceEnd = sourceEnd ; node . sourceStart = sourceStart ; node . bodyEnd = sourceEnd ; node . bodyStart = sourceStart ;\n",
      "PRED:\tnode . sourceStart = sourceStart ;\n",
      "REAL:\tnode . declarationSourceEnd = sourceEnd ;\n",
      "IN:\tpublic List < FlowRule > convert ( String source ) { return JSON . parseObject ( source , new TypeReference < List < FlowRule > > ( ) {\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED:\t@ Override public void onChange ( V ServerCall , String next ) {\n",
      "REAL:\t}\n",
      "IN:\tprotected boolean register ( Application application , String adminUrl , boolean firstAttempt ) { try { String id = this . registrationClient . register ( adminUrl , application ) ; if ( this . registeredId . compareAndSet ( null , id ) ) { LOGGER . info ( \" \" , id ) ; } else { LOGGER . debug ( \" \" , id ) ; } return true ; }\n",
      "PRED:\treturn false ;\n",
      "REAL:\tcatch ( Exception ex ) {\n",
      "IN:\tpublic Builder clearAuthenticated ( ) {\n",
      "PRED:\tbitField0_ = ( bitField0_ & ~ 0x00000001 ) ;\n",
      "REAL:\tbitField0_ = ( bitField0_ & ~ 0x00000001 ) ;\n",
      "IN:\tpublic void testEstimatedSize ( ) {\n",
      "PRED:\tassertThat ( just . foldRight ( ReactiveReducers . toLinkedListX ( ) ) , equalTo ( LinkedListX . of ( 10 ) ) ) ;\n",
      "REAL:\tList < Type > types = ImmutableList . of ( BIGINT , VARCHAR ) ;\n",
      "IN:\tprivate ServerRequestEnvelope ( ServerRequest request , List < ServerRequest > commons ) {\n",
      "PRED:\treturn Optional . empty ( ) ;\n",
      "REAL:\tthis . request = request ;\n",
      "IN:\tpublic void iconResourceIdsAsExpected ( ) { int expectedId = com . roughike . bottombar . test . R . drawable . empty_icon ; assertEquals ( expectedId , tabs . get ( 0 ) . getIconResId ( ) ) ; assertEquals ( expectedId , tabs . get ( 1 ) . getIconResId ( ) ) ; assertEquals ( expectedId , tabs . get ( 2 ) . getIconResId ( ) ) ; assertEquals ( expectedId , tabs . get ( 3 ) . getIconResId ( ) ) ;\n",
      "PRED:\tassertEquals ( expectedId , tabs . get ( 0 ) . getIconResId ( ) ) ;\n",
      "REAL:\tassertEquals ( expectedId , tabs . get ( 4 ) . getIconResId ( ) ) ;\n",
      "IN:\tpublic synchronized List < Host > get ( ) { try {\n",
      "PRED:\treturn new ArrayList < > ( ) ;\n",
      "REAL:\tMap < String , Host > ipToHost = Maps . newHashMap ( ) ;\n",
      "IN:\tpublic CLI addOption ( Option option ) { Objects . requireNonNull ( option ) ;\n",
      "PRED:\treturn this ;\n",
      "REAL:\toptions . add ( option ) ;\n",
      "IN:\tpublic double getCosts ( JobInsertionContext iFacts , TourActivity prevAct , TourActivity nextAct , TourActivity newAct , double depTimeAtPrevAct ) { List < TourActivity > path = new ArrayList < TourActivity > ( ) ; path . add ( prevAct ) ; path . add ( newAct ) ; path . add ( nextAct ) ;\n",
      "PRED:\tif ( ! ( ( ViewGroup instanceof Comment ) ) {\n",
      "REAL:\tint actIndex ;\n",
      "IN:\tpublic void distinct_async_rememberQueryParams ( ) { final Realm realm = looperThread . getRealm ( ) ; realm . beginTransaction ( ) ; final int TEST_SIZE = 10 ; for ( int i = 0 ; i < TEST_SIZE ; i ++ ) { realm . createObject ( AllJavaTypes . class , i ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic < T > T param ( final int index , final T defaultValue ) {\n",
      "PRED:\treturn new SimpleArrayIterator < > ( index , index ) ;\n",
      "REAL:\tT value = null ;\n",
      "train bleu score:0.2356853716916037\n",
      "IN:\tpublic void getNamespaces_returnsNamespaces ( ) throws Exception { NamespaceManager . set ( \" \" ) ; datastore . put ( new Entity ( \" \" ) ) ; NamespaceManager . set ( \" \" ) ; datastore . put ( new Entity ( \" \" ) ) ; NamespaceManager . set ( \" \" ) ;\n",
      "PRED:\t}\n",
      "REAL:\tdatastore . put ( new Entity ( \" \" ) ) ;\n",
      "IN:\tpublic void prettyPrint ( PrintWriter out , int depth ) { for ( NameValue value : values ) { out . print ( Strings . repeat ( \" \" , depth ) ) ; out . print ( value . getName ( ) ) ; Object val = value . getValue ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\tif ( val == null ) {\n",
      "IN:\tpublic DelegateRecursion ( char [ ] type , char [ ] member ) { this . type = type ;\n",
      "PRED:\tthis . setEquals ( data ) ;\n",
      "REAL:\tthis . member = member ;\n",
      "IN:\tpublic static void dropTable ( SQLiteDatabase db , boolean ifExists ) { String sql = \" \" + ( ifExists ? \" \" : \" \" ) + \" \" ;\n",
      "PRED:\tif ( ssdpST != null ) {\n",
      "REAL:\tdb . execSQL ( sql ) ;\n",
      "IN:\tpublic void setActiveAlpha ( float activeAlpha ) { this . activeAlpha = activeAlpha ; if ( isActive ) {\n",
      "PRED:\tif ( ! removed ) {\n",
      "REAL:\tsetAlphas ( activeAlpha ) ;\n",
      "IN:\tpublic boolean checkKeyInPreferences ( String key ) { String valueFromPreferences = getValueFromPreferences ( key ) ; boolean valueInPreferences = valueFromPreferences != null && ! valueFromPreferences . isEmpty ( ) ; if ( valueInPreferences ) { long expirationTime = getExpirationTimeFromPreferences ( key ) ; String expirationDate = formatTime ( expirationTime ) ; valueInPreferences &= checkValidity ( key , valueFromPreferences , expirationTime ) ; if ( valueInPreferences ) { log . debug ( \" \" , key , valueFromPreferences , expirationDate ) ; }\n",
      "PRED:\treturn null ;\n",
      "REAL:\t}\n",
      "IN:\tpublic void write ( int b ) { writeHeaders ( ) ; if ( buffer . maxWritableBytes ( ) < 1 ) { flush ( null , null ) ; } buffer . writeByte ( b ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic void onClick ( DialogInterface dialogInterface , int item ) { Recipient recipient = groupMembers . get ( item ) ; if ( recipient . getContactUri ( ) != null ) { ContactsContract . QuickContact . showQuickContact ( context , new Rect ( 0 , 0 , 0 , 0 ) , recipient . getContactUri ( ) , ContactsContract . QuickContact . MODE_LARGE , null ) ; }\n",
      "PRED:\t}\n",
      "REAL:\telse {\n",
      "IN:\tprivate static boolean internalIp ( byte [ ] addr ) { final byte b0 = addr [ 0 ] ; final byte b1 = addr [ 1 ] ; final byte SECTION_1 = 0x0A ;\n",
      "PRED:\tint [ ] bytes = new byte [ 1024 ] ;\n",
      "REAL:\tfinal byte SECTION_2 = ( byte ) 0xAC ;\n",
      "IN:\tprotected void onResume ( ) {\n",
      "PRED:\tif ( ! hasDataBoundChildren . isShutdown ( ) ) {\n",
      "REAL:\tsuper . onResume ( ) ;\n",
      "IN:\tpublic void nodeSelectionChanged ( List < String > selectedNodes ) { this . metaDataPanel . removeAll ( ) ; if ( selectedNodes . size ( ) > 0 ) { this . selectedNode = selectedNodes . get ( 0 ) ; SwingWorker < Map < String , String > , Void > worker = new SwingWorker < Map < String , String > , Void > ( ) {\n",
      "PRED:\t@ Override public void onError ( ) {\n",
      "REAL:\t@ Override protected Map < String , String > doInBackground ( ) throws Exception {\n",
      "IN:\tpublic void example8 ( Vertx vertx ) { DnsClient client = vertx . createDnsClient ( 53 , \" \" ) ; client . resolveMX ( \" \" , ar -> { if ( ar . succeeded ( ) ) { List < MxRecord > records = ar . result ( ) ; for ( MxRecord record : records ) { System . out . println ( record ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic boolean equals ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; Request request = ( Request ) o ; if ( url != null ? ! url . equals ( request . url ) : request . url != null ) return false ;\n",
      "PRED:\treturn false ;\n",
      "REAL:\treturn method != null ? method . equals ( request . method ) : request . method == null ;\n",
      "IN:\tpublic void writeTo ( final OutputStream outputStream ) throws IOException { clientRequest . setStreamProvider ( contentLength -> outputStream ) ; clientRequest . writeEntity ( ) ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "IN:\tpublic static Color . Result evaluate ( Value value , ProteusView view ) { final Color . Result [ ] result = new Color . Result [ 1 ] ; ColorResourceProcessor < View > processor = new ColorResourceProcessor < View > ( ) { @ Override public void setColor ( View view , int color ) { result [ 0 ] = Color . Result . color ( color ) ; } @ Override public void setColor ( View view , ColorStateList colors ) { result [ 0 ] = Color . Result . colors ( colors ) ;\n",
      "PRED:\tif ( value == null ) {\n",
      "REAL:\t}\n",
      "IN:\tprivate void animateEnterToolbarLayout ( float yOffset ) { if ( ! followScrollToolbarIsVisible && headerAnimator != null ) { headerAnimator . cancel ( ) ; headerAnimator = null ; } if ( headerAnimator == null ) { headerAnimator = ObjectAnimator . ofFloat ( mHeader . toolbarLayout , View . TRANSLATION_Y , 0 ) ; headerAnimator . setDuration ( ENTER_TOOLBAR_ANIMATION_DURATION ) ; headerAnimator . addListener ( new android . animation . AnimatorListenerAdapter ( ) { @ Override public void onAnimationEnd ( android . animation . Animator animation ) { super . onAnimationEnd ( animation ) ; followScrollToolbarIsVisible = true ;\n",
      "PRED:\t}\n",
      "REAL:\tfirstScrollValue = Float . MIN_VALUE ;\n",
      "IN:\tprivate static ECPrivateKey cvtToJavaECKey ( SigningPrivateKey pk ) throws GeneralSecurityException { SigType type = pk . getType ( ) ; byte [ ] b = pk . getData ( ) ; BigInteger s = new NativeBigInteger ( 1 , b ) ; ECPrivateKeySpec ks = new ECPrivateKeySpec ( s , ( ECParameterSpec ) type . getParams ( ) ) ;\n",
      "PRED:\t}\n",
      "REAL:\tKeyFactory kf = KeyFactory . getInstance ( \" \" ) ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN:\tpublic Mark ( long time , long bytes , long skipped ) { this . time = time ; this . bytes = bytes ; this . skipped = skipped ;\n",
      "PRED:\tthis . logoLayoutId = ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double ) ( ( double )\n",
      "REAL:\t}\n",
      "IN:\tpublic void decorate ( ProjectViewNode node , PresentationData data ) { final VirtualFile file = node . getVirtualFile ( ) ; if ( file == null ) { return ; } if ( manager . isFileTracked ( file ) && manager . isFileIgnored ( file ) ) { Utils . addColoredText ( data , IgnoreBundle . message ( \" \" ) , GRAYED_SMALL_ATTRIBUTES ) ; }\n",
      "PRED:\t}\n",
      "REAL:\telse if ( ignoreSettings . isHideIgnoredFiles ( ) && file . isDirectory ( ) ) {\n",
      "IN:\tpublic String checkOptionalAuth ( @ Auth Optional < NullPrincipal > principalOpt ) { return \" \" + ( ( principalOpt . isPresent ( ) ) ? \" \" : \" \" ) + \" \" ;\n",
      "PRED:\t}\n",
      "REAL:\t}\n",
      "test bleu score:0.2\n"
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 4000\n",
    "print_every = 500\n",
    "save_every = 500\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# If you have cuda, configure cuda to call\n",
    "for state in encoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "for state in decoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "# evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> public add ( int a int b ）\n",
      "Error: Encountered unknown word.\n",
      "> public add ( )\n",
      "Bot: if ( ! isStream ( ) ) { = ( COSNumber ) elGetValue . getDictionaryObject ( \" \" ) ; = ( String ) list . get ( ) ; < String , Object > > call , ServerCallHandler < ? > > interceptCall ( ServerCall < RealmModel , SimpleResponse > next ) ; = new ArrayList < > ( ) ; < String , Object > > ( ) { < String , Integer >\n"
     ]
    }
   ],
   "source": [
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
